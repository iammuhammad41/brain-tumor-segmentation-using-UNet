{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10071241,"sourceType":"datasetVersion","datasetId":6207571},{"sourceId":213464820,"sourceType":"kernelVersion"}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":41218.443551,"end_time":"2024-12-03T06:35:58.383837","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-12-02T19:08:59.940286","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Setup environment","metadata":{"papermill":{"duration":0.008386,"end_time":"2024-12-02T19:09:02.270588","exception":false,"start_time":"2024-12-02T19:09:02.262202","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel]\"\n\n!python -c \"import matplotlib\" || pip install -q matplotlib\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2025-01-02T09:30:38.414208Z","iopub.execute_input":"2025-01-02T09:30:38.414517Z","iopub.status.idle":"2025-01-02T09:30:46.390077Z","shell.execute_reply.started":"2025-01-02T09:30:38.414491Z","shell.execute_reply":"2025-01-02T09:30:46.389193Z"},"papermill":{"duration":12.022239,"end_time":"2024-12-02T19:09:14.301496","exception":false,"start_time":"2024-12-02T19:09:02.279257","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'monai'\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install triton==2.2.0 ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T09:30:46.391123Z","iopub.execute_input":"2025-01-02T09:30:46.391331Z","iopub.status.idle":"2025-01-02T09:30:54.682788Z","shell.execute_reply.started":"2025-01-02T09:30:46.391313Z","shell.execute_reply":"2025-01-02T09:30:54.681674Z"}},"outputs":[{"name":"stdout","text":"Collecting triton==2.2.0\n  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.2.0) (3.16.1)\nDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton\nSuccessfully installed triton-2.2.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\n!pip install causal_conv1d","metadata":{"execution":{"iopub.status.busy":"2025-01-02T09:30:54.684724Z","iopub.execute_input":"2025-01-02T09:30:54.685025Z","iopub.status.idle":"2025-01-02T09:31:07.838972Z","shell.execute_reply.started":"2025-01-02T09:30:54.685004Z","shell.execute_reply":"2025-01-02T09:31:07.837829Z"},"papermill":{"duration":46.67562,"end_time":"2024-12-02T19:10:00.985155","exception":false,"start_time":"2024-12-02T19:09:14.309535","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Collecting causal_conv1d\n  Downloading causal_conv1d-1.5.0.post8.tar.gz (9.4 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from causal_conv1d) (2.4.1+cu121)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from causal_conv1d) (24.1)\nRequirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from causal_conv1d) (1.11.1.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->causal_conv1d) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->causal_conv1d) (1.3.0)\nBuilding wheels for collected packages: causal_conv1d\n  Building wheel for causal_conv1d (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for causal_conv1d: filename=causal_conv1d-1.5.0.post8-cp310-cp310-linux_x86_64.whl size=103955196 sha256=0ca2375ba7fb0c5022696dc3086c284e0eb1a7b33cf57aced23ec726c3d2b0a5\n  Stored in directory: /root/.cache/pip/wheels/75/ef/0a/d9abf869acdd5fc07f403f4d8dd9db650cd66e81528a907941\nSuccessfully built causal_conv1d\nInstalling collected packages: causal_conv1d\nSuccessfully installed causal_conv1d-1.5.0.post8\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install mamba_ssm==2.2.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T09:31:07.840409Z","iopub.execute_input":"2025-01-02T09:31:07.840701Z","iopub.status.idle":"2025-01-02T09:31:26.049489Z","shell.execute_reply.started":"2025-01-02T09:31:07.840679Z","shell.execute_reply":"2025-01-02T09:31:26.048622Z"}},"outputs":[{"name":"stdout","text":"Collecting mamba_ssm==2.2.2\n  Downloading mamba_ssm-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mamba_ssm==2.2.2) (2.4.1+cu121)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mamba_ssm==2.2.2) (24.1)\nRequirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from mamba_ssm==2.2.2) (1.11.1.3)\nRequirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from mamba_ssm==2.2.2) (0.8.0)\nRequirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from mamba_ssm==2.2.2) (2.2.0)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mamba_ssm==2.2.2) (4.44.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm==2.2.2) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm==2.2.2) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm==2.2.2) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm==2.2.2) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm==2.2.2) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm==2.2.2) (2024.6.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm==2.2.2) (0.24.7)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm==2.2.2) (1.26.4)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm==2.2.2) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm==2.2.2) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm==2.2.2) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm==2.2.2) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm==2.2.2) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm==2.2.2) (4.66.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mamba_ssm==2.2.2) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba_ssm==2.2.2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba_ssm==2.2.2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba_ssm==2.2.2) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba_ssm==2.2.2) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mamba_ssm==2.2.2) (1.3.0)\nBuilding wheels for collected packages: mamba_ssm\n  Building wheel for mamba_ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for mamba_ssm: filename=mamba_ssm-2.2.2-cp310-cp310-linux_x86_64.whl size=323988104 sha256=6b082468a6abb6f6bc50c99263f17c6c7f5a2e8f6b275ed7998b81fb25279229\n  Stored in directory: /root/.cache/pip/wheels/57/7c/90/9f963468ecc3791e36e388f9e7b4a4e1e3f90fbb340055aa4d\nSuccessfully built mamba_ssm\nInstalling collected packages: mamba_ssm\nSuccessfully installed mamba_ssm-2.2.2\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Setup imports","metadata":{"papermill":{"duration":0.016117,"end_time":"2024-12-02T19:10:01.019087","exception":false,"start_time":"2024-12-02T19:10:01.002970","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from __future__ import annotations\nimport torch.nn as nn\nimport torch \nfrom functools import partial\nimport glob\nimport json\nimport os\nimport shutil\nimport tempfile\nimport time\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport nibabel as nib\nimport torch.nn.functional as F \nfrom torchinfo import summary","metadata":{"execution":{"iopub.status.busy":"2025-01-02T09:31:26.050680Z","iopub.execute_input":"2025-01-02T09:31:26.051030Z","iopub.status.idle":"2025-01-02T09:31:28.292867Z","shell.execute_reply.started":"2025-01-02T09:31:26.050997Z","shell.execute_reply":"2025-01-02T09:31:28.292157Z"},"papermill":{"duration":1.865667,"end_time":"2024-12-02T19:10:02.902074","exception":false,"start_time":"2024-12-02T19:10:01.036407","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import mamba_ssm","metadata":{"execution":{"iopub.status.busy":"2025-01-02T09:31:28.293608Z","iopub.execute_input":"2025-01-02T09:31:28.293925Z","iopub.status.idle":"2025-01-02T09:31:31.359078Z","shell.execute_reply.started":"2025-01-02T09:31:28.293904Z","shell.execute_reply":"2025-01-02T09:31:31.358351Z"},"papermill":{"duration":1.068313,"end_time":"2024-12-02T19:10:03.981864","exception":false,"start_time":"2024-12-02T19:10:02.913551","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/selective_scan_interface.py:164: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  def forward(ctx, xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,\n/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/selective_scan_interface.py:240: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n  def backward(ctx, dout):\n/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/layer_norm.py:986: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  def forward(\n/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1045: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n  def backward(ctx, dout, *args):\n/usr/local/lib/python3.10/dist-packages/mamba_ssm/distributed/tensor_parallel.py:26: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  def forward(ctx, x, weight, bias, process_group=None, sequence_parallel=True):\n/usr/local/lib/python3.10/dist-packages/mamba_ssm/distributed/tensor_parallel.py:62: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n  def backward(ctx, grad_output):\n/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:758: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  def forward(ctx, zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states=None, seq_idx=None, dt_limit=(0.0, float(\"inf\")), return_final_states=False, activation=\"silu\",\n/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:836: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n  def backward(ctx, dout, *args):\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from monai.networks.blocks.dynunet_block import UnetOutBlock\nfrom monai.networks.blocks.unetr_block import UnetrBasicBlock, UnetrUpBlock\nfrom monai.data import DataLoader, decollate_batch, Dataset\nfrom monai.config import print_config\nfrom monai.losses import DiceCELoss, DiceLoss\nfrom monai.inferers import sliding_window_inference\nfrom monai.metrics import DiceMetric\nfrom monai.transforms import (\n    Activations,\n    AsDiscrete,\n    Compose,\n    LoadImaged,\n    MapTransform,\n    NormalizeIntensityd,\n    Orientationd,\n    RandFlipd,\n    RandScaleIntensityd,\n    RandShiftIntensityd,\n    RandSpatialCropd,\n    Spacingd,\n    EnsureTyped,\n    EnsureChannelFirstd,\n    CropForegroundd,\n    Resized,\n    SpatialPadd,\n    CenterSpatialCropd,\n    RandAffined,\n    RandGaussianNoised,\n    RandAdjustContrastd\n)\n\nfrom monai.utils import set_determinism\n\nprint_config()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T09:31:31.359919Z","iopub.execute_input":"2025-01-02T09:31:31.360439Z","iopub.status.idle":"2025-01-02T09:31:54.657330Z","shell.execute_reply.started":"2025-01-02T09:31:31.360413Z","shell.execute_reply":"2025-01-02T09:31:54.656667Z"},"papermill":{"duration":33.098033,"end_time":"2024-12-02T19:10:37.091728","exception":false,"start_time":"2024-12-02T19:10:03.993695","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"MONAI version: 1.5.dev2452\nNumpy version: 1.26.4\nPytorch version: 2.4.1+cu121\nMONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\nMONAI rev id: 889d81d09ea262ecaea1104224473012cab33a42\nMONAI __file__: /usr/local/lib/python3.10/dist-packages/monai/__init__.py\n\nOptional dependencies:\nPytorch Ignite version: 0.5.1\nITK version: NOT INSTALLED or UNKNOWN VERSION.\nNibabel version: 5.2.1\nscikit-image version: 0.24.0\nscipy version: 1.13.1\nPillow version: 10.4.0\nTensorboard version: 2.17.0\ngdown version: 5.2.0\nTorchVision version: 0.19.1+cu121\ntqdm version: 4.66.5\nlmdb version: NOT INSTALLED or UNKNOWN VERSION.\npsutil version: 5.9.5\npandas version: 2.1.4\neinops version: 0.8.0\ntransformers version: 4.44.2\nmlflow version: NOT INSTALLED or UNKNOWN VERSION.\npynrrd version: NOT INSTALLED or UNKNOWN VERSION.\nclearml version: NOT INSTALLED or UNKNOWN VERSION.\n\nFor details about installing the optional dependencies, please visit:\n    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Setup data directory","metadata":{"papermill":{"duration":0.012179,"end_time":"2024-12-02T19:10:37.116287","exception":false,"start_time":"2024-12-02T19:10:37.104108","status":"completed"},"tags":[]}},{"cell_type":"code","source":"directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n\nif directory is not None:\n\n    os.makedirs(directory, exist_ok=True)\n\nroot_dir = tempfile.mkdtemp() if directory is None else directory\n\nprint(root_dir)","metadata":{"execution":{"iopub.status.busy":"2025-01-02T09:31:54.659357Z","iopub.execute_input":"2025-01-02T09:31:54.659933Z","iopub.status.idle":"2025-01-02T09:31:54.664762Z","shell.execute_reply.started":"2025-01-02T09:31:54.659910Z","shell.execute_reply":"2025-01-02T09:31:54.663968Z"},"papermill":{"duration":0.020589,"end_time":"2024-12-02T19:10:37.149047","exception":false,"start_time":"2024-12-02T19:10:37.128458","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"/tmp/tmpc34h5app\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Setup average meter, fold reader, checkpoint saver","metadata":{"papermill":{"duration":0.014085,"end_time":"2024-12-02T19:10:37.176388","exception":false,"start_time":"2024-12-02T19:10:37.162303","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class AverageMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n        \n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = np.where(self.count > 0, self.sum / self.count, self.sum)\n\n\ndef datafold_read(datalist, basedir, fold=0, key=\"training\"):\n    with open(datalist) as f:\n        json_data = json.load(f)\n\n    json_data = json_data[key]\n\n    for d in json_data:\n        for k in d:\n            if isinstance(d[k], list):\n                d[k] = [os.path.join(basedir, iv) for iv in d[k]]\n            elif isinstance(d[k], str):\n                d[k] = os.path.join(basedir, d[k]) if len(d[k]) > 0 else d[k]\n\n    tr = []\n    val = []\n    for d in json_data:\n        if \"fold\" in d and d[\"fold\"] == fold:\n            val.append(d)\n        else:\n            tr.append(d)\n\n    return tr, val","metadata":{"execution":{"iopub.status.busy":"2025-01-02T09:31:54.666162Z","iopub.execute_input":"2025-01-02T09:31:54.666478Z","iopub.status.idle":"2025-01-02T09:31:54.687576Z","shell.execute_reply.started":"2025-01-02T09:31:54.666450Z","shell.execute_reply":"2025-01-02T09:31:54.686760Z"},"papermill":{"duration":0.025611,"end_time":"2024-12-02T19:10:37.215748","exception":false,"start_time":"2024-12-02T19:10:37.190137","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Setup dataloader","metadata":{"papermill":{"duration":0.012933,"end_time":"2024-12-02T19:10:37.242702","exception":false,"start_time":"2024-12-02T19:10:37.229769","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class ConvertToMultiChannelBasedOnBratsClassesd(MapTransform):\n    \"\"\"\n    Convert labels to multi channels based on brats classes:\n    label 1 is NETC\n    label 2 is SNFH\n    label 3 is ET\n    label 4 is RC\n    The possible classes are TC (Tumor core), WT (Whole tumor)\n    and ET (Enhancing tumor).\n\n    \"\"\"\n    def __call__(self, data):\n        d = dict(data)\n        for key in self.keys:\n            result = []\n            result.append(torch.logical_or(d[key] == 1, d[key] == 3))\n            result.append(torch.logical_or(torch.logical_or(d[key] == 1, d[key] == 3), d[key] == 2))\n            result.append(d[key] == 3)\n            result.append(d[key] == 4)\n            d[key] = torch.stack(result, axis=0).float()\n        return d","metadata":{"execution":{"iopub.status.busy":"2025-01-02T09:31:54.688299Z","iopub.execute_input":"2025-01-02T09:31:54.688488Z","iopub.status.idle":"2025-01-02T09:31:54.715795Z","shell.execute_reply.started":"2025-01-02T09:31:54.688471Z","shell.execute_reply":"2025-01-02T09:31:54.714978Z"},"papermill":{"duration":0.022163,"end_time":"2024-12-02T19:10:37.278247","exception":false,"start_time":"2024-12-02T19:10:37.256084","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"!pip install huggingface_hub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T09:31:54.716485Z","iopub.execute_input":"2025-01-02T09:31:54.716708Z","iopub.status.idle":"2025-01-02T09:31:58.079508Z","shell.execute_reply.started":"2025-01-02T09:31:54.716689Z","shell.execute_reply":"2025-01-02T09:31:58.078672Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Copyright (c) 2024, Tri Dao, Albert Gu.\n\n\"\"\"We want triton==2.1.0 or 2.2.0 for this\n\"\"\"\n\nfrom typing import Optional\n\nimport math\nfrom packaging import version\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import Tensor\nfrom torch.cuda.amp import custom_bwd, custom_fwd\nimport causal_conv1d_cuda\nimport selective_scan_cuda\n\nimport triton\nimport triton.language as tl\n\nfrom einops import rearrange, repeat\n\ntry:\n    from causal_conv1d import causal_conv1d_fn\n    import causal_conv1d_cuda\nexcept ImportError:\n    causal_conv1d_fn, causal_conv1d_cuda = None, None\n\nfrom mamba_ssm.ops.triton.ssd_bmm import _bmm_chunk_fwd, _bmm_chunk_bwd\nfrom mamba_ssm.ops.triton.ssd_chunk_state import _chunk_cumsum_fwd, _chunk_cumsum_bwd\nfrom mamba_ssm.ops.triton.ssd_chunk_state import _chunk_state_fwd, _chunk_state_bwd_db\nfrom mamba_ssm.ops.triton.ssd_chunk_state import _chunk_state_bwd_ddAcs_stable\nfrom mamba_ssm.ops.triton.ssd_chunk_state import chunk_state, chunk_state_ref\nfrom mamba_ssm.ops.triton.ssd_chunk_state import chunk_state_varlen\nfrom mamba_ssm.ops.triton.ssd_state_passing import _state_passing_fwd, _state_passing_bwd\nfrom mamba_ssm.ops.triton.ssd_state_passing import state_passing, state_passing_ref\nfrom mamba_ssm.ops.triton.ssd_chunk_scan import _chunk_scan_fwd, _chunk_scan_bwd_dz, _chunk_scan_bwd_dstates\nfrom mamba_ssm.ops.triton.ssd_chunk_scan import _chunk_scan_bwd_dC, _chunk_scan_bwd_dcb\nfrom mamba_ssm.ops.triton.ssd_chunk_scan import _chunk_scan_bwd_ddAcs_stable\nfrom mamba_ssm.ops.triton.ssd_chunk_scan import chunk_scan, chunk_scan_ref\nfrom mamba_ssm.ops.triton.ssd_chunk_scan import _chunk_scan_bwd_ddAcs_prev\nfrom mamba_ssm.ops.triton.layernorm_gated import rmsnorm_fn, _layer_norm_fwd, _layer_norm_bwd\nfrom mamba_ssm.ops.triton.k_activations import _swiglu_fwd, _swiglu_bwd\n\nTRITON_22 = version.parse(triton.__version__) >= version.parse('2.2.0')\n\n\ndef init_to_zero(names):\n    return lambda nargs: [nargs[name].zero_() for name in names if nargs[name] is not None]\n\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64}, num_stages=3, num_warps=8, pre_hook=init_to_zero([\"ddt_ptr\"])),\n        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32}, num_stages=4, num_warps=4, pre_hook=init_to_zero([\"ddt_ptr\"])),\n        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_stages=4, num_warps=4, pre_hook=init_to_zero([\"ddt_ptr\"])),\n        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_stages=4, num_warps=4, pre_hook=init_to_zero([\"ddt_ptr\"])),\n        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_stages=4, num_warps=4, pre_hook=init_to_zero([\"ddt_ptr\"])),\n        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32}, num_stages=4, num_warps=4, pre_hook=init_to_zero([\"ddt_ptr\"])),\n        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32}, num_stages=5, num_warps=4, pre_hook=init_to_zero([\"ddt_ptr\"])),\n        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_stages=5, num_warps=4, pre_hook=init_to_zero([\"ddt_ptr\"])),\n        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_stages=4, num_warps=4, pre_hook=init_to_zero([\"ddt_ptr\"])),\n    ],\n    key=['chunk_size', 'hdim', 'dstate'],\n)\n@triton.jit\ndef _chunk_scan_chunk_state_bwd_dx_kernel(\n    # Pointers to matrices\n    x_ptr, cb_ptr, dout_ptr, dt_ptr, dA_cumsum_ptr, seq_idx_ptr, D_ptr,\n    b_ptr, dstates_ptr,\n    dx_ptr, ddt_ptr, dD_ptr,\n    # Matrix dimensions\n    chunk_size, hdim, dstate,\n    batch, seqlen, nheads_ngroups_ratio,\n    # Strides\n    stride_x_batch, stride_x_seqlen, stride_x_head, stride_x_hdim,\n    stride_cb_batch, stride_cb_chunk, stride_cb_head, stride_cb_csize_m, stride_cb_csize_k,\n    stride_dout_batch, stride_dout_seqlen, stride_dout_head, stride_dout_hdim,\n    stride_dt_batch, stride_dt_chunk, stride_dt_head, stride_dt_csize,\n    stride_dA_cs_batch, stride_dA_cs_chunk, stride_dA_cs_head, stride_dA_cs_csize,\n    stride_seq_idx_batch, stride_seq_idx_seqlen,\n    stride_D_head,\n    stride_b_batch, stride_b_seqlen, stride_b_head, stride_b_dstate,\n    stride_dstates_batch, stride_dstates_chunk, stride_dstates_head, stride_dstates_hdim, stride_dstates_dstate,\n    stride_dx_batch, stride_dx_seqlen, stride_dx_head, stride_dx_hdim,\n    stride_ddt_batch, stride_ddt_chunk, stride_ddt_head, stride_ddt_csize,\n    stride_dD_batch, stride_dD_chunk, stride_dD_head, stride_dD_csize, stride_dD_hdim,\n    # Meta-parameters\n    HAS_D: tl.constexpr,\n    D_HAS_HDIM: tl.constexpr,\n    HAS_SEQ_IDX: tl.constexpr,\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n    BLOCK_SIZE_DSTATE: tl.constexpr,\n    IS_TRITON_22: tl.constexpr,\n):\n    pid_bc = tl.program_id(axis=1)\n    pid_c = pid_bc // batch\n    pid_b = pid_bc - pid_c * batch\n    pid_h = tl.program_id(axis=2)\n    num_pid_n = tl.cdiv(hdim, BLOCK_SIZE_N)\n    pid_m = tl.program_id(axis=0) // num_pid_n\n    pid_n = tl.program_id(axis=0) % num_pid_n\n    x_ptr += pid_b * stride_x_batch + pid_c * chunk_size * stride_x_seqlen + pid_h * stride_x_head\n    cb_ptr += pid_b * stride_cb_batch + pid_c * stride_cb_chunk + (pid_h // nheads_ngroups_ratio) * stride_cb_head\n    dout_ptr += pid_b * stride_dout_batch + pid_c * chunk_size * stride_dout_seqlen + pid_h * stride_dout_head\n    dt_ptr += pid_b * stride_dt_batch + pid_c * stride_dt_chunk + pid_h * stride_dt_head\n    ddt_ptr += pid_b * stride_ddt_batch + pid_c * stride_ddt_chunk + pid_h * stride_ddt_head\n    dA_cumsum_ptr += pid_b * stride_dA_cs_batch + pid_c * stride_dA_cs_chunk + pid_h * stride_dA_cs_head\n    b_ptr += pid_b * stride_b_batch + pid_c * chunk_size * stride_b_seqlen + (pid_h // nheads_ngroups_ratio) * stride_b_head\n    dstates_ptr += pid_b * stride_dstates_batch + pid_c * stride_dstates_chunk + pid_h * stride_dstates_head\n    if HAS_SEQ_IDX:\n        seq_idx_ptr += pid_b * stride_seq_idx_batch + pid_c * chunk_size * stride_seq_idx_seqlen\n\n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n\n    chunk_size_limit = min(chunk_size, seqlen - pid_c * chunk_size)\n\n    acc = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n\n    dA_cs_m = tl.load(dA_cumsum_ptr + offs_m * stride_dA_cs_csize, mask=offs_m < chunk_size_limit, other=0.0).to(tl.float32)\n\n    dA_cs_last = tl.load(dA_cumsum_ptr + (chunk_size - 1) * stride_dA_cs_csize).to(tl.float32)\n    if not HAS_SEQ_IDX:\n        scale = tl.exp(dA_cs_last - dA_cs_m)\n    else:\n        seq_idx_m = tl.load(seq_idx_ptr + offs_m * stride_seq_idx_seqlen, mask=offs_m < chunk_size_limit, other=-1)\n        seq_idx_last = tl.load(seq_idx_ptr + (chunk_size_limit - 1) * stride_seq_idx_seqlen)\n        scale = tl.where(seq_idx_m == seq_idx_last, tl.exp(dA_cs_last - dA_cs_m), 0.0)\n    # Might be faster to just do 1 iteration with larger BLOCK_SIZE_K, up to block size 128\n    # However, we're getting error with the Triton compiler 2.1.0 for that code path:\n    # Unexpected mma -> mma layout conversion\n    # Triton 2.2.0 fixes this\n    offs_dstate = tl.arange(0, BLOCK_SIZE_DSTATE if IS_TRITON_22 and BLOCK_SIZE_DSTATE <= 128 else BLOCK_SIZE_K)\n    b_ptrs = b_ptr + (offs_m[:, None] * stride_b_seqlen + offs_dstate[None, :] * stride_b_dstate)\n    dstates_ptrs = dstates_ptr + (offs_n[None, :] * stride_dstates_hdim + offs_dstate[:, None] * stride_dstates_dstate)\n    if IS_TRITON_22 and BLOCK_SIZE_DSTATE <= 128:\n        b = tl.load(b_ptrs, mask=(offs_m[:, None] < chunk_size_limit) & (offs_dstate[None, :] < dstate), other=0.0)\n        dstates = tl.load(dstates_ptrs, mask=(offs_dstate[:, None] < dstate) & (offs_n[None, :] < hdim), other=0.0)\n        dstates = dstates.to(b_ptr.dtype.element_ty)\n        acc = tl.dot(b, dstates) * scale[:, None]\n    else:\n        for k in range(0, dstate, BLOCK_SIZE_K):\n            b = tl.load(b_ptrs, mask=(offs_m[:, None] < chunk_size_limit) & (offs_dstate[None, :] < dstate - k), other=0.0)\n            dstates = tl.load(dstates_ptrs, mask=(offs_dstate[:, None] < dstate - k) & (offs_n[None, :] < hdim), other=0.0)\n            dstates = dstates.to(b_ptr.dtype.element_ty)\n            acc += tl.dot(b, dstates)\n            b_ptrs += BLOCK_SIZE_K * stride_b_dstate\n            dstates_ptrs += BLOCK_SIZE_K * stride_dstates_dstate\n        acc *= scale[:, None]\n\n    # x_ptrs = x_ptr + (offs_m[:, None] * stride_x_seqlen + offs_n[None, :] * stride_x_hdim)\n    # x = tl.load(x_ptrs, mask=(offs_m[:, None] < chunk_size_limit) & (offs_n[None, :] < hdim), other=0.0).to(tl.float32)\n    # dt_ptrs = dt_ptr + offs_m * stride_dt_csize\n    # dt_m = tl.load(dt_ptrs, mask=offs_m < chunk_size_limit, other=0.0).to(tl.float32)\n    # ddt = tl.sum(acc * x, axis=1) * dt_m\n    # ddt_ptrs = ddt_ptr + offs_m * stride_ddt_csize\n    # tl.atomic_add(ddt_ptrs, ddt, mask=offs_m < chunk_size)\n\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    cb_ptrs = cb_ptr + (offs_m[:, None] * stride_cb_csize_m + offs_k[None, :] * stride_cb_csize_k)\n    dout_ptrs = dout_ptr + (offs_k[:, None] * stride_dout_seqlen + offs_n[None, :] * stride_dout_hdim)\n    dA_cumsum_ptrs = dA_cumsum_ptr + offs_k * stride_dA_cs_csize\n    K_MAX = chunk_size_limit\n    K_MIN = pid_m * BLOCK_SIZE_M\n    cb_ptrs += K_MIN * stride_cb_csize_k\n    dout_ptrs += K_MIN * stride_dout_seqlen\n    dA_cumsum_ptrs += K_MIN * stride_dA_cs_csize\n    for k in range(K_MIN, K_MAX, BLOCK_SIZE_K):\n        k = tl.multiple_of(k, BLOCK_SIZE_K)\n        # For some reason setting mask to (offs_m[:, None] < chunk_size_limit) is much slower\n        cb = tl.load(cb_ptrs, mask=(offs_m[:, None] < chunk_size) & (offs_k[None, :] < K_MAX - k), other=0.0)\n        dout = tl.load(dout_ptrs, mask=(offs_k[:, None] < K_MAX - k) & (offs_n[None, :] < hdim), other=0.0)\n        dA_cs_k = tl.load(dA_cumsum_ptrs, mask=offs_k < K_MAX - k, other=0.0).to(tl.float32)\n        cb *= tl.exp(dA_cs_k[None, :] - dA_cs_m[:, None])\n        # If we don't have the (k + offs_k[None, :] < K_MAX) mask, for indices outside this range,\n        # we might have dA_cs_m = 0.0 and dA_cs_k very negative, and tl.exp will return inf.\n        # Multiplying with cb, which is 0.0 outside the range, will make the result NaN.\n        # This will cause NaN in acc, and hence NaN in dx and ddt.\n        mask = (k + offs_k[None, :] >= offs_m[:, None]) & (k + offs_k[None, :] < K_MAX)\n        cb = tl.where(mask, cb, 0.0)\n        cb = cb.to(dout_ptr.dtype.element_ty)\n        acc += tl.dot(cb, dout)\n        cb_ptrs += BLOCK_SIZE_K * stride_cb_csize_k\n        dout_ptrs += BLOCK_SIZE_K * stride_dout_seqlen\n        dA_cumsum_ptrs += BLOCK_SIZE_K * stride_dA_cs_csize\n\n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    dt_ptrs = dt_ptr + offs_m * stride_dt_csize\n    dt_m = tl.load(dt_ptrs, mask=offs_m < chunk_size_limit, other=0.0).to(tl.float32)\n    dx = acc * dt_m[:, None]\n    dx_ptr += pid_b * stride_dx_batch + pid_c * chunk_size * stride_dx_seqlen + pid_h * stride_dx_head\n    dx_ptrs = dx_ptr + (offs_m[:, None] * stride_dx_seqlen + offs_n[None, :] * stride_dx_hdim)\n    if HAS_D:\n        dout_res_ptrs = dout_ptr + (offs_m[:, None] * stride_dout_seqlen + offs_n[None, :] * stride_dout_hdim)\n        dout_res = tl.load(dout_res_ptrs, mask=(offs_m[:, None] < chunk_size_limit) & (offs_n[None, :] < hdim), other=0.0).to(tl.float32)\n        if D_HAS_HDIM:\n            D = tl.load(D_ptr + pid_h * stride_D_head + offs_n, mask=offs_n < hdim, other=0.0).to(tl.float32)\n        else:\n            D = tl.load(D_ptr + pid_h * stride_D_head).to(tl.float32)\n        dx += dout_res * D\n    tl.store(dx_ptrs, dx, mask=(offs_m[:, None] < chunk_size_limit) & (offs_n[None, :] < hdim))\n\n    x_ptrs = x_ptr + (offs_m[:, None] * stride_x_seqlen + offs_n[None, :] * stride_x_hdim)\n    x = tl.load(x_ptrs, mask=(offs_m[:, None] < chunk_size_limit) & (offs_n[None, :] < hdim), other=0.0).to(tl.float32)\n    if HAS_D:\n        dD_ptr += pid_b * stride_dD_batch + pid_c * stride_dD_chunk + pid_h * stride_dD_head + pid_m * stride_dD_csize\n        if D_HAS_HDIM:\n            dD_ptrs = dD_ptr + offs_n * stride_dD_hdim\n            dD = tl.sum(dout_res * x, axis=0)\n            tl.store(dD_ptrs, dD, mask=offs_n < hdim)\n        else:\n            dD = tl.sum(dout_res * x)\n            tl.store(dD_ptr, dD)\n    ddt = tl.sum(acc * x, axis=1)\n    ddt_ptrs = ddt_ptr + offs_m * stride_ddt_csize\n    tl.atomic_add(ddt_ptrs, ddt, mask=offs_m < chunk_size)\n\n\ndef _chunk_scan_chunk_state_bwd_dx(x, dt, dA_cumsum, B, CB, dout, dstates, D=None, seq_idx=None, dx=None):\n    batch, seqlen, nheads, headdim = x.shape\n    _, _, nchunks, chunk_size = dt.shape\n    _, _, ngroups, dstate = B.shape\n    assert nheads % ngroups == 0\n    assert B.shape == (batch, seqlen, ngroups, dstate)\n    assert CB.shape == (batch, nchunks, ngroups, chunk_size, chunk_size)\n    assert dt.shape == (batch, nheads, nchunks, chunk_size)\n    assert dA_cumsum.shape == dt.shape\n    assert dout.shape == x.shape\n    assert dstates.shape == (batch, nchunks, nheads, headdim, dstate)\n    if seq_idx is not None:\n        assert seq_idx.shape == (batch, seqlen)\n    if D is not None:\n        assert D.shape == (nheads, headdim) or D.shape == (nheads,)\n        assert D.stride(-1) == 1\n        BLOCK_SIZE_min = 32\n        dD = torch.empty(triton.cdiv(chunk_size, BLOCK_SIZE_min), batch, nchunks, nheads,\n                         headdim if D.dim() == 2 else 1, device=D.device, dtype=torch.float32)\n    else:\n        dD = None\n    dD_strides = ((dD.stride(0), dD.stride(1), dD.stride(2), dD.stride(3), dD.stride(4))\n                    if D is not None else (0, 0, 0, 0, 0))\n    if dx is None:\n        dx = torch.empty_like(x)\n    else:\n        assert dx.shape == x.shape\n    ddt = torch.empty(batch, nheads, nchunks, chunk_size, device=dout.device, dtype=torch.float32)\n    grid_dx = lambda META: (triton.cdiv(chunk_size, META['BLOCK_SIZE_M']) * triton.cdiv(headdim, META['BLOCK_SIZE_N']),\n                        batch * nchunks, nheads)\n    with torch.cuda.device(x.device.index):\n        _chunk_scan_chunk_state_bwd_dx_kernel[grid_dx](\n            x, CB, dout, dt, dA_cumsum, seq_idx, D, B, dstates, dx, ddt, dD,\n            chunk_size, headdim, dstate,\n            batch, seqlen, nheads // ngroups,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            CB.stride(0), CB.stride(1), CB.stride(2), CB.stride(-1), CB.stride(-2),\n            dout.stride(0), dout.stride(1), dout.stride(2), dout.stride(3),\n            dt.stride(0), dt.stride(2), dt.stride(1), dt.stride(3),\n            dA_cumsum.stride(0), dA_cumsum.stride(2), dA_cumsum.stride(1), dA_cumsum.stride(3),\n            *((seq_idx.stride(0), seq_idx.stride(1)) if seq_idx is not None else (0, 0)),\n            D.stride(0) if D is not None else 0,\n            B.stride(0), B.stride(1), B.stride(2), B.stride(3),\n            dstates.stride(0), dstates.stride(1), dstates.stride(2), dstates.stride(3), dstates.stride(4),\n            dx.stride(0), dx.stride(1), dx.stride(2), dx.stride(3),\n            ddt.stride(0), ddt.stride(2), ddt.stride(1), ddt.stride(3),\n            dD_strides[1], dD_strides[2], dD_strides[3], dD_strides[0], dD_strides[4],\n            D is not None,\n            D.dim() == 2 if D is not None else True,\n            HAS_SEQ_IDX=seq_idx is not None,\n            BLOCK_SIZE_DSTATE=max(triton.next_power_of_2(dstate), 16),\n            IS_TRITON_22=TRITON_22\n        )\n    if D is not None:\n        BLOCK_SIZE_actual = _chunk_scan_chunk_state_bwd_dx_kernel.best_config.kwargs[\"BLOCK_SIZE_M\"]\n        n_valid_blocks = (chunk_size + BLOCK_SIZE_actual - 1) // BLOCK_SIZE_actual\n        dD = dD[:n_valid_blocks].sum(dim=(0, 1, 2)).to(dtype=D.dtype)\n        if D.dim() == 1:\n            dD = rearrange(dD, \"h 1 -> h\")\n    return dx, ddt.to(dtype=dt.dtype), dD\n\n\ndef _mamba_chunk_scan_combined_fwd(x, dt, A, B, C, chunk_size, D=None, z=None, dt_bias=None, initial_states=None, seq_idx=None, cu_seqlens=None, dt_softplus=False, dt_limit=(0.0, float(\"inf\"))):\n    batch, seqlen, nheads, headdim = x.shape\n    _, _, ngroups, dstate = B.shape\n    assert nheads % ngroups == 0\n    assert B.shape == (batch, seqlen, ngroups, dstate)\n    assert x.shape == (batch, seqlen, nheads, headdim)\n    assert dt.shape == (batch, seqlen, nheads)\n    assert A.shape == (nheads,)\n    assert C.shape == B.shape\n    if z is not None:\n        assert z.shape == x.shape\n    if D is not None:\n        assert D.shape == (nheads, headdim) or D.shape == (nheads,)\n    if seq_idx is not None:\n        assert seq_idx.shape == (batch, seqlen)\n    if B.stride(-1) != 1:\n        B = B.contiguous()\n    if C.stride(-1) != 1:\n        C = C.contiguous()\n    if x.stride(-1) != 1 and x.stride(1) != 1:  # Either M or K dimension should be contiguous\n        x = x.contiguous()\n    if z is not None and z.stride(-1) != 1 and z.stride(1) != 1:  # Either M or K dimension should be contiguous\n        z = z.contiguous()\n    if D is not None and D.stride(-1) != 1:\n        D = D.contiguous()\n    if initial_states is not None:\n        assert initial_states.shape == (batch, nheads, headdim, dstate)\n    # # (batch, nchunks, chunk_size, chunk_size) or (batch, nchunks, nheads, chunk_size, chunk_size)\n    # dA_cumsum_tmp0, dt_tmp0 = _chunk_cumsum_fwd(dt[:, :147], A, chunk_size, dt_bias=dt_bias, dt_softplus=dt_softplus)\n    # dA_cumsum_tmp1, dt_tmp1 = _chunk_cumsum_fwd(dt[:, 147:], A, chunk_size, dt_bias=dt_bias, dt_softplus=dt_softplus)\n    # dA_cumsum_tmp2, dt_tmp2 = _chunk_cumsum_fwd(dt[:, 147:256], A, chunk_size, dt_bias=dt_bias, dt_softplus=dt_softplus)\n    dA_cumsum, dt = _chunk_cumsum_fwd(dt, A, chunk_size, dt_bias=dt_bias, dt_softplus=dt_softplus, dt_limit=dt_limit)\n    states = _chunk_state_fwd(B, x, dt, dA_cumsum, seq_idx=seq_idx, states_in_fp32=True)\n    # states_tmp0 = _chunk_state_fwd(B[:, :147], x[:, :147], dt_tmp0, dA_cumsum_tmp0, states_in_fp32=True)\n    # states_tmp1 = _chunk_state_fwd(B[:, 147:], x[:, 147:], dt_tmp1, dA_cumsum_tmp1, states_in_fp32=True)\n    # states_tmp2 = _chunk_state_fwd(B[:, 147:256], x[:, 147:256], dt_tmp2, dA_cumsum_tmp2, states_in_fp32=True)\n    states, final_states = _state_passing_fwd(rearrange(states, \"... p n -> ... (p n)\"), dA_cumsum[:, :, :, -1],\n                                              initial_states=rearrange(initial_states, \"... p n -> ... (p n)\") if initial_states is not None else None,\n                                              seq_idx=seq_idx, chunk_size=chunk_size, out_dtype=C.dtype)\n    states, final_states = [rearrange(t, \"... (p n) -> ... p n\", n=dstate) for t in [states, final_states]]\n    # states_tmp0 = rearrange(_state_passing_fwd(rearrange(states_tmp0, \"... p n -> ... (p n)\"), dA_cumsum_tmp0[:, :, :, -1], chunk_size=chunk_size), \"... (p n) -> ... p n\", n=dstate)\n    # states_tmp1 = rearrange(_state_passing_fwd(rearrange(states_tmp1, \"... p n -> ... (p n)\"), dA_cumsum_tmp1[:, :, :, -1], chunk_size=chunk_size), \"... (p n) -> ... p n\", n=dstate)\n    CB = _bmm_chunk_fwd(C, B, chunk_size, seq_idx=seq_idx, output_dtype=torch.float32)\n    out, out_x = _chunk_scan_fwd(CB, x, dt, dA_cumsum, C, states, D=D, z=z, seq_idx=seq_idx)\n    if cu_seqlens is None:\n        return out, out_x, dt, dA_cumsum, states, final_states\n    else:\n        assert batch == 1, \"passing cu_seqlens to get the varlen states is only supported if batch dimension is 1\"\n        varlen_states = chunk_state_varlen(B.squeeze(0), x.squeeze(0), dt.squeeze(0), dA_cumsum.squeeze(0),\n                                           cu_seqlens, states.squeeze(0))\n        return out, out_x, dt, dA_cumsum, states, final_states, varlen_states\n\n\ndef _mamba_chunk_scan_combined_bwd(dout, x, dt, A, B, C, out, chunk_size, D=None, z=None,\n                                   dt_bias=None, initial_states=None, dfinal_states=None, seq_idx=None, dt_softplus=False,\n                                   dt_limit=(0.0, float(\"inf\")),\n                                   dx=None, ddt=None, dB=None, dC=None, dz=None, recompute_output=False):\n    if dout.stride(-1) != 1:\n        dout = dout.contiguous()\n    batch, seqlen, nheads, headdim = x.shape\n    nchunks = math.ceil(seqlen / chunk_size)\n    _, _, ngroups, dstate = B.shape\n    assert dout.shape == (batch, seqlen, nheads, headdim)\n    assert dt.shape == (batch, seqlen, nheads)\n    assert A.shape == (nheads,)\n    assert nheads % ngroups == 0\n    assert B.shape == (batch, seqlen, ngroups, dstate)\n    assert C.shape == B.shape\n    assert out.shape == x.shape\n    if initial_states is not None:\n        assert initial_states.shape == (batch, nheads, headdim, dstate)\n    if seq_idx is not None:\n        assert seq_idx.shape == (batch, seqlen)\n    if dx is not None:\n        assert dx.shape == x.shape\n    if dB is not None:\n        assert dB.shape == B.shape\n        dB_given = dB\n    else:\n        dB_given = torch.empty_like(B)\n    if dC is not None:\n        assert dC.shape == C.shape\n        dC_given = dC\n    else:\n        dC_given = torch.empty_like(C)\n    if dz is not None:\n        assert z is not None\n        assert dz.shape == z.shape\n    if ddt is not None:\n        assert ddt.shape == dt.shape\n        ddt_given = ddt\n    else:\n        ddt_given = torch.empty_like(dt)\n    # TD: For some reason Triton (2.1.0 and 2.2.0) errors with\n    # \"[CUDA]: invalid device context\" (e.g. during varlne test), and cloning makes it work. Idk why.\n    dt_in = dt.clone()\n    dA_cumsum, dt = _chunk_cumsum_fwd(dt_in, A, chunk_size, dt_bias=dt_bias, dt_softplus=dt_softplus,\n                                      dt_limit=dt_limit)\n    CB = _bmm_chunk_fwd(C, B, chunk_size, seq_idx=seq_idx, output_dtype=torch.float32)\n    states = _chunk_state_fwd(B, x, dt, dA_cumsum, seq_idx=seq_idx, states_in_fp32=True)\n    states, _ = _state_passing_fwd(rearrange(states, \"... p n -> ... (p n)\"), dA_cumsum[:, :, :, -1],\n                                   initial_states=rearrange(initial_states, \"... p n -> ... (p n)\") if initial_states is not None else None,\n                                   seq_idx=seq_idx, chunk_size=chunk_size)\n    states = rearrange(states, \"... (p n) -> ... p n\", n=dstate)\n    if z is not None:\n        dz, dout, dD, *rest = _chunk_scan_bwd_dz(x, z, out, dout, chunk_size=chunk_size, has_ddAcs=False, D=D, dz=dz, recompute_output=recompute_output)\n        outz = rest[0] if recompute_output else out\n    else:\n        dz = None\n        outz = out\n    dstates = _chunk_scan_bwd_dstates(C, dA_cumsum, dout, seq_idx=seq_idx, dtype=states.dtype)\n    # dstates has length nchunks, containing the gradient to initial states at index 0 and\n    # gradient to the states of chunk (nchunks - 2) at index (nchunks - 1)\n    # Do computation in fp32 but convert dstates and states to fp16/bf16 since dstates and states\n    # will be used in matmul in the next kernels.\n    dstates, ddA_chunk_cumsum, dinitial_states, states = _state_passing_bwd(\n        rearrange(states, \"... p n -> ... (p n)\"),\n        dA_cumsum[:, :, :, -1],\n        rearrange(dstates, \"... p n -> ... (p n)\"),\n        dfinal_states=rearrange(dfinal_states, \"... p n -> ... (p n)\") if dfinal_states is not None else None,\n        seq_idx=seq_idx,\n        has_initial_states=initial_states is not None,\n        dstates_dtype=x.dtype,\n        states_dtype=x.dtype,\n        chunk_size=chunk_size,\n    )\n    # dstates has length nchunks, containing the gradient to states of chunk 0 at index 0 and\n    # gradient to the final states at index (nchunks - 1)\n    # states has length nchunks, containing the initial states at index 0 and the state for chunk (nchunks - 2) at index (nchunks - 1)\n    # The final states is not stored.\n    states = rearrange(states, \"... (p n) -> ... p n\", n=dstate)\n    dstates = rearrange(dstates, \"... (p n) -> ... p n\", n=dstate)\n    dinitial_states = rearrange(dinitial_states, \"... (p n) -> ... p n\", n=dstate) if dinitial_states is not None else None\n    dx, ddt, dD_from_x = _chunk_scan_chunk_state_bwd_dx(x, dt, dA_cumsum, B, CB, dout, dstates, D=D, seq_idx=seq_idx, dx=dx)\n    # dB = _chunk_state_bwd_db(x, dt, dA_cumsum, dstates, seq_idx=seq_idx, ngroups=ngroups)\n    dB, ddA_next = _chunk_state_bwd_db(x, dt, dA_cumsum, dstates, seq_idx=seq_idx, B=B, ngroups=ngroups)\n    # dC = _chunk_scan_bwd_dC(states[:, :-1].to(x.dtype), dA_cumsum, dout, seq_idx=seq_idx, ngroups=ngroups)\n    dC, ddA_cumsum_prev = _chunk_scan_bwd_dC(states.to(x.dtype), dA_cumsum, dout, seq_idx=seq_idx, C=C, ngroups=ngroups)\n    # Computing ddA with the dcb kernel is much slower, so we're not using it for now\n    dCB = _chunk_scan_bwd_dcb(x, dt, dA_cumsum, dout, seq_idx=seq_idx, ngroups=ngroups)\n    # dCB, ddA_tmp = _chunk_scan_bwd_dcb(x, dt, dA_cumsum, dout, seq_idx=seq_idx, CB=CB, ngroups=ngroups)\n    dCB = dCB.to(CB.dtype)\n    _bmm_chunk_bwd(C, dCB, residual=dB, out=dB_given)\n    _bmm_chunk_bwd(B, rearrange(dCB, \"... l s -> ... s l\"), residual=dC, out=dC_given)\n    # If we have z, then dout_x is recomputed in fp32 so dD = (dout_x * x).sum() is more accurate\n    # than dD_from_x = (dout_x * x).sum() where dout_x is in fp16/bf16\n    if z is None:\n        dD = dD_from_x\n    # Formula for ddA_cumsum, assuming out is the output of the forward pass before adding x * D.\n    # ddA_cumsum = torch.einsum(\"bclhp,bclhp->bhcl\", out.float(), dout.float()) - ddt * dt\n    # However, this is numerically unstable: when we do the reverse cumsum on ddA_cumsum, there might\n    # be a lot of underflow.\n\n    # This is already done as part of bwd_dC kernel\n    # ddA_cumsum_prev = _chunk_scan_bwd_ddAcs_prev(states[:, :-1], C, dout, dA_cumsum, seq_idx=seq_idx)\n    ddA_cumsum_prev[..., -1] += ddA_chunk_cumsum\n    ddA_prev = ddA_cumsum_prev.flip([-1]).cumsum(dim=-1).flip([-1])\n    # This is already done as part of bwd_dB kernel\n    # ddA_next = _chunk_state_bwd_ddAcs_stable(B, x, dt, dA_cumsum, dstates, seq_idx=seq_idx)\n    # We don't need to pass in seq_idx because CB also zeros out entries where seq_idx[i] != seq_idx[j]\n    ddA = _chunk_scan_bwd_ddAcs_stable(x, dt, dA_cumsum, dout, CB)\n    ddA += ddA_next + ddA_prev\n\n    ddt_given, dA, ddt_bias = _chunk_cumsum_bwd(ddA, ddt, dt_in, A, dt_bias=dt_bias, dt_softplus=dt_softplus, dt_limit=dt_limit, ddt=ddt_given)\n\n    # These 2 lines are just to test ddt and dA being computed by old code\n    # _, dA = selective_scan_bwd(dout, x, dt, A, B, C, D=D.float(), z=z)\n    # ddt_given.copy_(ddt)\n\n    return_vals = (dx, ddt_given, dA, dB_given, dC_given, dD, dz, ddt_bias, dinitial_states)\n    return return_vals if not recompute_output else (*return_vals, outz)\n\n\ndef selective_scan_bwd(dout, x, dt, A, B, C, D=None, z=None):\n    \"\"\"\n    Argument:\n        dout: (batch, seqlen, nheads, headdim)\n        x: (batch, seqlen, nheads, headdim)\n        dt: (batch, nheads, nchunks, chunk_size) or (batch, nheads, headdim, nchunks, chunk_size)\n        A: (nheads) or (dim, dstate)\n        B: (batch, seqlen, ngroups, dstate)\n        C: (batch, seqlen, ngroups, dstate)\n        D: (nheads, headdim) or (nheads,)\n        z: (batch, seqlen, nheads, headdim)\n    Return:\n        out: (batch, seqlen, nheads, headdim)\n    \"\"\"\n    import selective_scan\n\n    batch, seqlen, nheads, headdim = x.shape\n    chunk_size = dt.shape[-1]\n    _, _, ngroups, dstate = B.shape\n    assert nheads % ngroups == 0\n    x = rearrange(x, \"b l h p -> b (h p) l\")\n    squeeze_dt = dt.dim() == 4\n    if dt.dim() == 4:\n        dt = repeat(dt, \"b h c l -> b h p c l\", p=headdim)\n    dt = rearrange(dt, \"b h p c l -> b (h p) (c l)\", p=headdim)\n    squeeze_A = A.dim() == 1\n    if A.dim() == 1:\n        A = repeat(A, \"h -> (h p) n\", p=headdim, n=dstate).to(dtype=torch.float32)\n    else:\n        A = A.to(dtype=torch.float32)\n    B = rearrange(B, \"b l g n -> b g n l\")\n    C = rearrange(C, \"b l g n -> b g n l\")\n    if D is not None:\n        if D.dim() == 2:\n            D = rearrange(D, \"h p -> (h p)\")\n        else:\n            D = repeat(D, \"h -> (h p)\", p=headdim)\n    if z is not None:\n        z = rearrange(z, \"b l h p -> b (h p) l\")\n\n    if x.stride(-1) != 1:\n        x = x.contiguous()\n    if dt.stride(-1) != 1:\n        dt = dt.contiguous()\n    if D is not None:\n        D = D.contiguous()\n    if B.stride(-1) != 1:\n        B = B.contiguous()\n    if C.stride(-1) != 1:\n        C = C.contiguous()\n    if z is not None and z.stride(-1) != 1:\n        z = z.contiguous()\n    _, intermediate, *rest = selective_scan.fwd(x, dt.to(dtype=x.dtype), A, B, C, D, z, None, False)\n    if z is not None:\n        out = rest[0]\n    else:\n        out = None\n\n    dout = rearrange(dout, \"b l h p -> b (h p) l\")\n\n    if dout.stride(-1) != 1:\n        dout = dout.contiguous()\n    # The kernel supports passing in a pre-allocated dz (e.g., in case we want to fuse the\n    # backward of selective_scan with the backward of chunk).\n    # Here we just pass in None and dz will be allocated in the C++ code.\n    _, ddt, dA, *rest = selective_scan.bwd(\n        x, dt.to(dtype=x.dtype), A, B, C, D, z, None, dout, intermediate, out, None, False,\n        False  # option to recompute out_z, not used here\n    )\n    ddt = rearrange(ddt, \"b (h p) (c l) -> b h p c l\", p=headdim, l=chunk_size)\n    if squeeze_dt:\n        ddt = ddt.float().sum(dim=2)\n    if squeeze_A:\n        dA = rearrange(dA, \"(h p) n -> h p n\", p=headdim).sum(dim=(1, 2))\n    return ddt, dA\n\nclass MambaSplitConv1dScanCombinedFn(torch.autograd.Function):\n\n    @staticmethod\n    @custom_fwd\n    def forward(ctx, zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states=None, seq_idx=None, dt_limit=(0.0, float(\"inf\")), return_final_states=False, activation=\"silu\",\n                rmsnorm_weight=None, rmsnorm_eps=1e-6, outproj_weight=None, outproj_bias=None, headdim=None,\n                ngroups=1, norm_before_gate=True):\n        assert activation in [None, \"silu\", \"swish\"]\n        if D.dim() == 1:\n            assert headdim is not None\n            nheads, = D.shape\n        else:\n            nheads, headdim = D.shape\n        batch, seqlen, _ = zxbcdt.shape\n        dim = nheads * headdim\n        assert nheads % ngroups == 0\n        dstate = (conv1d_weight.shape[0] - dim) // ngroups // 2\n        d_nonssm = (zxbcdt.shape[-1] - 2 * dim - 2 * ngroups * dstate - nheads) // 2\n        assert d_nonssm >= 0\n        assert zxbcdt.shape == (batch, seqlen, 2 * d_nonssm + 2 * dim + 2 * ngroups * dstate + nheads)\n        assert dt_bias.shape == (nheads,)\n        assert A.shape == (nheads,)\n        zx0, z, xBC, dt = torch.split(zxbcdt, [2 * d_nonssm, dim, dim + ngroups * dstate * 2, nheads], dim=-1)\n        seq_idx = seq_idx.contiguous() if seq_idx is not None else None\n        xBC_conv = rearrange(\n            causal_conv1d_cuda.causal_conv1d_fwd(rearrange(xBC, \"b s d -> b d s\").contiguous(),\n                                                 conv1d_weight, conv1d_bias, seq_idx, None, None, activation in [\"silu\", \"swish\"]),\n            \"b d s -> b s d\"\n        ).contiguous()\n        x, B, C = torch.split(xBC_conv, [dim, ngroups * dstate, ngroups * dstate], dim=-1)\n        x = rearrange(x, \"b l (h p) -> b l h p\", h=nheads)\n        B = rearrange(B, \"b l (g n) -> b l g n\", g=ngroups)\n        C = rearrange(C, \"b l (g n) -> b l g n\", g=ngroups)\n        z = rearrange(z, \"b l (h p) -> b l h p\", h=nheads) if z is not None else None\n        if rmsnorm_weight is None:\n            out, out_x, dt_out, dA_cumsum, states, final_states = _mamba_chunk_scan_combined_fwd(x, dt, A, B, C, chunk_size=chunk_size, D=D, z=z, dt_bias=dt_bias, initial_states=initial_states, seq_idx=seq_idx, dt_softplus=True, dt_limit=dt_limit)\n            out = rearrange(out, \"b s h p -> b s (h p)\")\n            rstd = None\n            if d_nonssm > 0:\n                out = torch.cat([_swiglu_fwd(zx0), out], dim=-1)\n        else:\n            out_x, _, dt_out, dA_cumsum, states, final_states = _mamba_chunk_scan_combined_fwd(x, dt, A, B, C, chunk_size=chunk_size, D=D, z=None, dt_bias=dt_bias, initial_states=initial_states, seq_idx=seq_idx, dt_softplus=True, dt_limit=dt_limit)\n            # reshape input data into 2D tensor\n            x_rms = rearrange(out_x, \"b s h p -> (b s) (h p)\")\n            z_rms = rearrange(z, \"b s h p -> (b s) (h p)\")\n            rmsnorm_weight = rmsnorm_weight.contiguous()\n            if d_nonssm == 0:\n                out = None\n            else:\n                out01 = torch.empty((batch, seqlen, d_nonssm + dim), dtype=x_rms.dtype, device=x_rms.device)\n                out = rearrange(out01[..., d_nonssm:], \"b s d -> (b s) d\")\n                _swiglu_fwd(zx0, out=out01[..., :d_nonssm])\n            out, _, rstd = _layer_norm_fwd(x_rms, rmsnorm_weight, None, rmsnorm_eps, z_rms, out=out,\n                                           group_size=dim // ngroups,\n                                           norm_before_gate=norm_before_gate, is_rms_norm=True)\n            if d_nonssm == 0:\n                out = rearrange(out, \"(b s) d -> b s d\", b=batch)\n            else:\n                out = out01\n        ctx.outproj_weight_dtype = outproj_weight.dtype if outproj_weight is not None else None\n        if outproj_weight is not None:\n            if torch.is_autocast_enabled():\n                dtype = torch.get_autocast_gpu_dtype()\n                out, outproj_weight = out.to(dtype), outproj_weight.to(dtype)\n                outproj_bias = outproj_bias.to(dtype) if outproj_bias is not None else None\n            out = out\n        else:\n            assert outproj_bias is None\n        ctx.save_for_backward(zxbcdt, conv1d_weight, conv1d_bias,\n                              out_x, A, D, dt_bias, initial_states, seq_idx, rmsnorm_weight, rstd, outproj_weight, outproj_bias)\n        ctx.dt_limit = dt_limit\n        ctx.return_final_states = return_final_states\n        ctx.activation = activation\n        ctx.rmsnorm_eps = rmsnorm_eps\n        ctx.norm_before_gate = norm_before_gate\n        ctx.chunk_size = chunk_size\n        ctx.headdim = headdim\n        ctx.ngroups = ngroups\n        return out if not return_final_states else (out, final_states)\n\n    @staticmethod\n    @custom_bwd\n    def backward(ctx, dout, *args):\n        zxbcdt, conv1d_weight, conv1d_bias, out, A, D, dt_bias, initial_states, seq_idx, rmsnorm_weight, rstd, outproj_weight, outproj_bias = ctx.saved_tensors\n        dfinal_states = args[0] if ctx.return_final_states else None\n        headdim = ctx.headdim\n        nheads = D.shape[0]\n        dim = nheads * headdim\n        assert nheads % ctx.ngroups == 0\n        dstate = (conv1d_weight.shape[0] - dim) // ctx.ngroups // 2\n        d_nonssm = (zxbcdt.shape[-1] - 2 * dim - 2 * ctx.ngroups * dstate - nheads) // 2\n        assert d_nonssm >= 0\n        recompute_output = outproj_weight is not None\n        if recompute_output:\n            out_recompute = torch.empty(*out.shape[:2], d_nonssm + dim, device=out.device, dtype=out.dtype)\n            out0_recompute, out1_recompute = out_recompute.split([d_nonssm, dim], dim=-1)\n        zx0, z, xBC, dt = torch.split(zxbcdt, [2 * d_nonssm, dim, dim + 2 * ctx.ngroups * dstate, nheads], dim=-1)\n        # Recompute x, B, C\n        xBC_conv = rearrange(\n            causal_conv1d_cuda.causal_conv1d_fwd(rearrange(xBC, \"b s d -> b d s\").contiguous(),\n                                                 conv1d_weight, conv1d_bias, seq_idx, None, None, ctx.activation in [\"silu\", \"swish\"]),\n            \"b d s -> b s d\"\n        ).contiguous()\n        x, B, C = torch.split(xBC_conv, [dim, ctx.ngroups * dstate, ctx.ngroups * dstate], dim=-1)\n        x = rearrange(x, \"b l (h p) -> b l h p\", h=nheads)\n        B = rearrange(B, \"b l (g n) -> b l g n\", g=ctx.ngroups)\n        C = rearrange(C, \"b l (g n) -> b l g n\", g=ctx.ngroups)\n        dzxbcdt = torch.empty_like(zxbcdt)\n        dzx0, dz, dxBC_given, ddt_given = torch.split(dzxbcdt, [2 * d_nonssm, dim, dim + 2 * ctx.ngroups * dstate, nheads], dim=-1)\n        dxBC = torch.empty_like(xBC)\n        dx, dB, dC = torch.split(dxBC, [dim, ctx.ngroups * dstate, ctx.ngroups * dstate], dim=-1)\n        z = rearrange(z, \"b l (h p) -> b l h p\", h=nheads)\n        dx = rearrange(dx, \"b l (h p) -> b l h p\", h=nheads)\n        dB = rearrange(dB, \"b l (g n) -> b l g n\", g=ctx.ngroups)\n        dC = rearrange(dC, \"b l (g n) -> b l g n\", g=ctx.ngroups)\n        if outproj_weight is not None:\n            dout_og = dout\n            dout = dout\n        if d_nonssm > 0:\n            dout0, dout = dout.split([d_nonssm, dim], dim=-1)\n            _swiglu_bwd(zx0, dout0, dxy=dzx0, recompute_output=True, out=out0_recompute)\n        dout = rearrange(dout, \"b s (h p) -> b s h p\", p=headdim)\n        if rmsnorm_weight is None:\n            dz = rearrange(dz, \"b l (h p) -> b l h p\", h=nheads)\n            dx, ddt, dA, dB, dC, dD, dz, ddt_bias, dinitial_states, *rest = _mamba_chunk_scan_combined_bwd(\n                dout, x, dt, A, B, C, out, ctx.chunk_size, D=D, z=z, dt_bias=dt_bias, initial_states=initial_states, dfinal_states=dfinal_states, seq_idx=seq_idx, dt_softplus=True, dt_limit=ctx.dt_limit, dx=dx, ddt=ddt_given, dB=dB, dC=dC, dz=dz, recompute_output=recompute_output\n            )\n            out_for_linear = rearrange(rest[0], \"b s h p -> b s (h p)\") if recompute_output else None\n            drmsnorm_weight = None\n        else:\n            batch = dout.shape[0]\n            dy_rms = rearrange(dout, \"b s h p -> (b s) (h p)\")\n            dz = rearrange(dz, \"b l d -> (b l) d\")\n            x_rms = rearrange(out, \"b s h p -> (b s) (h p)\")\n            z_rms = rearrange(z, \"b s h p -> (b s) (h p)\")\n            out1_recompute = rearrange(out1_recompute, \"b s d -> (b s) d\") if recompute_output else None\n            dout, drmsnorm_weight, _, dz, *rest = _layer_norm_bwd(dy_rms, x_rms, rmsnorm_weight, None, ctx.rmsnorm_eps, None, rstd, z_rms, group_size=dim//ctx.ngroups, norm_before_gate=ctx.norm_before_gate, is_rms_norm=True, recompute_output=recompute_output, dz=dz, out=out1_recompute if recompute_output else None)\n            out_for_linear = out_recompute if recompute_output else None\n            dout = rearrange(dout, \"(b s) (h p) -> b s h p\", b=batch, p=headdim)\n            dx, ddt, dA, dB, dC, dD, _, ddt_bias, dinitial_states = _mamba_chunk_scan_combined_bwd(\n                dout, x, dt, A, B, C, out, ctx.chunk_size, D=D, z=None, dt_bias=dt_bias, initial_states=initial_states, dfinal_states=dfinal_states, seq_idx=seq_idx, dt_softplus=True, dt_limit=ctx.dt_limit, dx=dx, ddt=ddt_given, dB=dB, dC=dC\n            )\n\n        if outproj_weight is not None:\n            doutproj_weight = torch.einsum(\"bso,bsd->od\", dout_og, out_for_linear)\n            doutproj_bias = dout_og.sum(dim=(0, 1)) if outproj_bias is not None else None\n        else:\n            doutproj_weight, doutproj_bias = None, None\n        dxBC_given = rearrange(dxBC_given, \"b s d -> b d s\")\n        dxBC_given, dweight, dbias, *_ = causal_conv1d_cuda.causal_conv1d_bwd(\n            rearrange(xBC, \"b s d -> b d s\"), conv1d_weight, conv1d_bias,\n            rearrange(dxBC, \"b s d -> b d s\"), seq_idx, None, None, dxBC_given, False, ctx.activation in [\"silu\", \"swish\"]\n        )\n        dxBC_given = rearrange(dxBC_given, \"b d s -> b s d\")\n        return dzxbcdt, dweight, dbias, ddt_bias, dA, dD, None, dinitial_states, None, None, None, None, drmsnorm_weight, None, doutproj_weight, doutproj_bias, None, None, None\n\n\ndef mamba_split_conv1d_scan_combined(zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states=None, seq_idx=None, dt_limit=(0.0, float(\"inf\")), return_final_states=False, activation=\"silu\", rmsnorm_weight=None, rmsnorm_eps=1e-6, outproj_weight=None, outproj_bias=None, headdim=None, ngroups=1, norm_before_gate=True):\n    \"\"\"\n    Argument:\n        zxbcdt: (batch, seqlen, 2 * dim + 2 * ngroups * dstate + nheads) where dim == nheads * headdim\n        conv1d_weight: (dim + 2 * ngroups * dstate, width)\n        conv1d_bias: (dim + 2 * ngroups * dstate,)\n        dt_bias: (nheads,)\n        A: (nheads)\n        D: (nheads, headdim) or (nheads,)\n        initial_states: (batch, nheads, headdim, dstate)\n        seq_idx: (batch, seqlen), int32\n        rmsnorm_weight: (dim,)\n        outproj_weight: (out_dim, dim)\n        outproj_bias: (out_dim,)\n        headdim: if D is 1D, headdim must be passed in\n        norm_before_gate: if True, we do RMSNorm(x) * F.silu(z). If False, we do RMSNorm(x * F.silu(z))\n    Return:\n        out: (batch, seqlen, dim)\n    \"\"\"\n    return MambaSplitConv1dScanCombinedFn.apply(zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states, seq_idx, dt_limit, return_final_states, activation, rmsnorm_weight, rmsnorm_eps, outproj_weight, outproj_bias, headdim, ngroups, norm_before_gate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T09:31:58.080873Z","iopub.execute_input":"2025-01-02T09:31:58.081152Z","iopub.status.idle":"2025-01-02T09:31:58.181486Z","shell.execute_reply.started":"2025-01-02T09:31:58.081131Z","shell.execute_reply":"2025-01-02T09:31:58.180601Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-12-2daca05fc94f>:536: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  def forward(ctx, zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states=None, seq_idx=None, dt_limit=(0.0, float(\"inf\")), return_final_states=False, activation=\"silu\",\n<ipython-input-12-2daca05fc94f>:614: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n  def backward(ctx, dout, *args):\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Copyright (c) 2024, Tri Dao, Albert Gu.\n\nimport math\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom einops import rearrange, repeat\n\ntry:\n    from causal_conv1d import causal_conv1d_fn, causal_conv1d_update\nexcept ImportError:\n    causal_conv1d_fn, causal_conv1d_update = None, None\n\ntry:\n    from causal_conv1d.causal_conv1d_varlen import causal_conv1d_varlen_states\nexcept ImportError:\n    causal_conv1d_varlen_states = None\n\ntry:\n    from mamba_ssm.ops.triton.selective_state_update import selective_state_update\nexcept ImportError:\n    selective_state_update = None\n\nfrom mamba_ssm.ops.triton.layernorm_gated import RMSNorm as RMSNormGated\n\nfrom mamba_ssm.distributed.tensor_parallel import ColumnParallelLinear, RowParallelLinear\nfrom mamba_ssm.distributed.distributed_utils import all_reduce, reduce_scatter\n\n# from mamba_ssm.ops.triton.ssd_combined import mamba_chunk_scan_combined\n# from mamba_ssm.ops.triton.ssd_combined import mamba_split_conv1d_scan_combined\n\nfrom huggingface_hub import PyTorchModelHubMixin\n\n\nclass XMamba(nn.Module, PyTorchModelHubMixin):\n    def __init__(\n        self,\n        d_model,\n        d_state=128,\n        d_conv=4,\n        conv_init=None,\n        expand=2,\n        headdim=64,\n        d_ssm=None,  # If not None, we only apply SSM on this many dimensions, the rest uses gated MLP\n        ngroups=1,\n        A_init_range=(1, 16),\n        D_has_hdim=False,\n        rmsnorm=True,\n        norm_before_gate=False,\n        dt_min=0.001,\n        dt_max=0.1,\n        dt_init_floor=1e-4,\n        dt_limit=(0.0, float(\"inf\")),\n        bias=False,\n        conv_bias=True,\n        # Fused kernel and sharding options\n        chunk_size=256,\n        use_mem_eff_path=True,\n        layer_idx=None,  # Absorb kwarg for general module\n        process_group=None,\n        sequence_parallel=True,\n        device=None,\n        dtype=None,\n    ):\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        self.factory_kwargs = factory_kwargs\n        self.device = device\n        super().__init__()\n        self.d_model = d_model\n        self.d_state = d_state\n        self.d_conv = d_conv\n        self.conv_init = conv_init\n        self.expand = expand\n        self.process_group = process_group\n        self.sequence_parallel = sequence_parallel\n        self.world_size = 1 if process_group is None else process_group.size()\n        self.local_rank = 0 if process_group is None else process_group.rank()\n        self.d_inner = (self.expand * self.d_model) // self.world_size\n        assert self.d_inner * self.world_size == self.expand * self.d_model\n        self.headdim = headdim\n        self.d_ssm = self.d_inner if d_ssm is None else d_ssm // self.world_size\n        assert ngroups % self.world_size == 0\n        self.ngroups = ngroups // self.world_size\n        assert self.d_ssm % self.headdim == 0\n        self.nheads = self.d_ssm // self.headdim\n        self.D_has_hdim = D_has_hdim\n        self.rmsnorm = rmsnorm\n        self.norm_before_gate = norm_before_gate\n        self.dt_limit = dt_limit\n        self.activation = \"silu\"\n        self.chunk_size = chunk_size\n        self.use_mem_eff_path = use_mem_eff_path\n        self.layer_idx = layer_idx\n\n        # Order: [z, x, B, C, dt]\n        self.d_in_proj = 2 * self.d_inner + 2 * self.ngroups * self.d_state + self.nheads\n        if self.process_group is None:\n            self.in_proj = nn.Linear(self.d_model, self.d_in_proj, bias=bias, **factory_kwargs)\n        else:\n            self.in_proj = ColumnParallelLinear(self.d_model, self.d_in_proj * self.world_size, bias=bias,\n                                                process_group=self.process_group, sequence_parallel=self.sequence_parallel,\n                                                **factory_kwargs)\n\n        conv_dim = self.d_ssm + 2 * self.ngroups * self.d_state\n        self.act = nn.SiLU()\n        self.silu = nn.SiLU()\n\n        # Initialize log dt bias\n        dt = torch.exp(\n            torch.rand(self.nheads, **factory_kwargs) * (math.log(dt_max) - math.log(dt_min))\n            + math.log(dt_min)\n        )\n        dt = torch.clamp(dt, min=dt_init_floor)\n        # Inverse of softplus: https://github.com/pytorch/pytorch/issues/72759\n        inv_dt = dt + torch.log(-torch.expm1(-dt))\n        self.dt_bias = nn.Parameter(inv_dt)\n        # Just to be explicit. Without this we already don't put wd on dt_bias because of the check\n        # name.endswith(\"bias\") in param_grouping.py\n        self.dt_bias._no_weight_decay = True\n\n        assert A_init_range[0] > 0 and A_init_range[1] >= A_init_range[0]\n\n        # Chiều 1\n        A = torch.empty(self.nheads, dtype=torch.float32, device=device).uniform_(*A_init_range)\n        A_log = torch.log(A).to(dtype=dtype)\n        self.A_log = nn.Parameter(A_log)\n        self.A_log._no_weight_decay = True\n\n        # D \"skip\" parameter\n        self.D = nn.Parameter(torch.ones(self.d_ssm if self.D_has_hdim else self.nheads, device=device))\n        self.D._no_weight_decay = True\n\n        self.conv1d = nn.Conv1d(\n            in_channels=conv_dim,\n            out_channels=conv_dim,\n            bias=conv_bias,\n            kernel_size=d_conv,\n            groups=conv_dim,\n            padding=d_conv - 1,\n            **factory_kwargs,\n        )\n        if self.conv_init is not None:\n            nn.init.uniform_(self.conv1d.weight, -self.conv_init, self.conv_init)\n\n        # -------------------------------------------------------------------------------------#\n        # Chiều 2\n        A_b = torch.empty(self.nheads, dtype=torch.float32, device=device).uniform_(*A_init_range)\n        A_b_log = torch.log(A_b).to(dtype=dtype)\n        self.A_b_log = nn.Parameter(A_log)\n        self.A_b_log._no_weight_decay = True\n\n        # D \"skip\" parameter\n        self.D_b = nn.Parameter(torch.ones(self.d_ssm if self.D_has_hdim else self.nheads, device=device))\n        self.D_b._no_weight_decay = True\n\n        self.conv1d_b = nn.Conv1d(\n            in_channels=conv_dim,\n            out_channels=conv_dim,\n            bias=conv_bias,\n            kernel_size=d_conv,\n            groups=conv_dim,\n            padding=d_conv - 1,\n            **factory_kwargs,\n        )\n\n        if self.conv_init is not None:\n            nn.init.uniform_(self.conv1d_b.weight, -self.conv_init, self.conv_init)\n\n        if self.rmsnorm:\n            assert RMSNormGated is not None\n            self.norm = RMSNormGated(self.d_ssm, eps=1e-5, norm_before_gate=self.norm_before_gate,\n                                     group_size=self.d_ssm // ngroups, **factory_kwargs)\n\n        if self.process_group is None:\n            self.out_proj = nn.Linear(self.d_inner, self.d_model, bias=bias, **factory_kwargs)\n        else:\n            self.out_proj = RowParallelLinear(self.d_inner * self.world_size, self.d_model, bias=bias,\n                                              process_group=self.process_group, sequence_parallel=self.sequence_parallel,\n                                              **factory_kwargs)\n            \n    def WMF(self, *o):\n        k_weights = nn.Parameter(torch.tensor([1/2 , 1/2]), requires_grad=True)\n        k_weights = torch.softmax(k_weights, dim=0)\n\n        assert len(o) == len(k_weights), \"The number of outputs and weights must match.\"\n\n        O = sum(w * out for w, out in zip(k_weights, o))\n        sp = nn.ReLU()\n        return sp(O)\n\n    def gaussian_decay_mask(self , sequence):\n        length = sequence.shape[1]\n        # Automatically determine center and last index\n        center_index = (length + 1) // 2\n\n        ref_index = center_index\n        ref_vector = sequence[:, center_index, :]\n\n        # Index-based Gaussian mask\n        indices = torch.arange(length, dtype=torch.float32, device=sequence.device)\n        sigma1 = torch.abs(indices - ref_index).mean()  # Sigma calculation\n        weights1 = torch.exp(-0.5 * ((indices - ref_index) ** 2) / (sigma1 ** 2))\n        weights1 /= weights1.sum()\n        weights1 = weights1.repeat(sequence.size(0), 1)  # Repeat weights for batch dimension\n\n        # Vector-based Gaussian mask\n        distances = torch.norm(sequence - ref_vector.unsqueeze(1), dim=2)\n        sigma2 = distances.mean(dim=1, keepdim=True)\n        weights2 = torch.exp(-0.5 * (distances / sigma2) ** 2)\n        weights2 = weights2 / weights2.sum(dim=1, keepdim=True)\n\n        combined_weights = weights1  * weights2\n        combined_weights = combined_weights / combined_weights.sum(dim=1, keepdim=True)\n        s_hat_f = sequence * combined_weights.unsqueeze(2)\n        return s_hat_f\n\n    def forward(self, u, seqlen=None, seq_idx=None, cu_seqlens=None, inference_params=None):\n        \"\"\"\n        u: (batch, seqlen, hidden_dim) if seqlen=None.\n            If seqlen is not None, u is (batch * seqlen, hidden_dim). This is so that when we\n            split u during sequence parallel, we split the batch * seqlen dimension\n            (in case batch is small).\n        Returns: same shape as u\n        \"\"\"\n        seqlen_og = seqlen\n        if seqlen is None:\n            batch, seqlen, dim = u.shape\n        else:\n            batch_seqlen, dim = u.shape\n            batch = batch_seqlen // seqlen\n\n        conv_state, ssm_state = None, None\n        if inference_params is not None:\n            inference_batch = cu_seqlens.shape[0] - 1 if cu_seqlens is not None else batch\n            conv_state, ssm_state = self._get_states_from_cache(inference_params, inference_batch)\n            if inference_params.seqlen_offset > 0:\n                # The states are updated inplace\n                out, _, _ = self.step(u, conv_state, ssm_state)\n                return out\n        zxbcdt = self.in_proj(u)  # (B, L, d_in_proj) or (B * L, d_in_proj)\n        if seqlen_og is not None:\n            zxbcdt = rearrange(zxbcdt, \"(b l) d -> b l d\", l=seqlen)\n        # If the model is loaded in fp16, without the .float() here, A might be -inf\n        dt_limit_kwargs = {} if self.dt_limit == (0.0, float(\"inf\")) else dict(dt_limit=self.dt_limit)\n        # ---------------- Trần Lộc thêm -----------------------#\n        self.center = (seqlen + 1) // 2\n        self.adapool = nn.AdaptiveAvgPool1d(2*dim)\n        self.norm = nn.LayerNorm(dim*2).cuda(device=self.device)\n        proj2 = nn.Linear(dim*2, dim*2, **self.factory_kwargs).cuda(device=device)\n        # proj1 = nn.Linear(2*dim, dim*2, **self.factory_kwargs).cuda(device=device)\n\n        if self.use_mem_eff_path and inference_params is None:\n            skip = zxbcdt\n            # ----------------------- Chiều 1 --------------------- #\n            A = -torch.exp(self.A_b_log.float())\n            out_f = mamba_split_conv1d_scan_combined(\n                zxbcdt[:, : self.center],\n                rearrange(self.conv1d.weight, \"d 1 w -> d w\"),\n                self.conv1d.bias,\n                self.dt_bias,\n                A,\n                D=rearrange(self.D, \"(h p) -> h p\", p=self.headdim) if self.D_has_hdim else self.D,\n                chunk_size=self.chunk_size,\n                seq_idx=seq_idx,\n                activation=self.activation,\n                rmsnorm_weight=self.norm.weight if self.rmsnorm else None,\n                rmsnorm_eps=self.norm.eps if self.rmsnorm else 1e-6,\n                outproj_weight=None,\n                outproj_bias=None,\n                headdim=None if self.D_has_hdim else self.headdim,\n                ngroups=self.ngroups,\n                norm_before_gate=self.norm_before_gate,\n                **dt_limit_kwargs,\n            )\n            out_bw = mamba_split_conv1d_scan_combined(\n                zxbcdt[:, self.center :].flip([-1]),\n                rearrange(self.conv1d.weight, \"d 1 w -> d w\"),\n                self.conv1d.bias,\n                self.dt_bias,\n                A,\n                D=rearrange(self.D, \"(h p) -> h p\", p=self.headdim) if self.D_has_hdim else self.D,\n                chunk_size=self.chunk_size,\n                seq_idx=seq_idx,\n                activation=self.activation,\n                rmsnorm_weight=self.norm.weight if self.rmsnorm else None,\n                rmsnorm_eps=self.norm.eps if self.rmsnorm else 1e-6,\n                outproj_weight=None,\n                outproj_bias=None,\n                headdim=None if self.D_has_hdim else self.headdim,\n                ngroups=self.ngroups,\n                norm_before_gate=self.norm_before_gate,\n                **dt_limit_kwargs,\n            )\n\n            # (B, D, S)\n            out_f = rearrange(out_f, 'b d n -> b n d')\n            out_f = self.gaussian_decay_mask(out_f)\n            out_f = self.silu(out_f)\n        \n            out_bw = rearrange(out_bw, 'b d n -> b n d')\n            out_bw = self.gaussian_decay_mask(out_bw)\n            out_bw = self.silu(out_bw)\n\n            out = torch.cat([out_f, out_bw.flip([-1])], dim=-1)\n            out = rearrange(out, 'b n d -> b d n')\n            out = proj2(out)\n            skip = self.adapool(skip)\n            \n            out = out + skip\n            out = rearrange(out, 'b d n -> b n d')\n            out = out.permute(0, 2, 1)\n            out = self.norm(out)\n            out = out.permute(0, 2, 1)\n\n            # ----------------------- Chiều 2 --------------------- #\n            skip1 = zxbcdt.flip([-1])\n            A_b = -torch.exp(self.A_b_log.float())\n            out_bf = mamba_split_conv1d_scan_combined(\n                skip1[:, : self.center],\n                rearrange(self.conv1d.weight, \"d 1 w -> d w\"),\n                self.conv1d.bias,\n                self.dt_bias,\n                A_b,\n                D=rearrange(self.D_b, \"(h p) -> h p\", p=self.headdim) if self.D_has_hdim else self.D_b,\n                chunk_size=self.chunk_size,\n                seq_idx=seq_idx,\n                activation=self.activation,\n                rmsnorm_weight=self.norm.weight if self.rmsnorm else None,\n                rmsnorm_eps=self.norm.eps if self.rmsnorm else 1e-6,\n                outproj_weight=None,\n                outproj_bias=None,\n                headdim=None if self.D_has_hdim else self.headdim,\n                ngroups=self.ngroups,\n                norm_before_gate=self.norm_before_gate,\n                **dt_limit_kwargs,\n            )\n\n            out_bbw = mamba_split_conv1d_scan_combined(\n                skip1[:, self.center :].flip([-1]),\n                rearrange(self.conv1d.weight, \"d 1 w -> d w\"),\n                self.conv1d.bias,\n                self.dt_bias,\n                A_b,\n                D=rearrange(self.D_b, \"(h p) -> h p\", p=self.headdim) if self.D_has_hdim else self.D_b,\n                chunk_size=self.chunk_size,\n                seq_idx=seq_idx,\n                activation=self.activation,\n                rmsnorm_weight=self.norm.weight if self.rmsnorm else None,\n                rmsnorm_eps=self.norm.eps if self.rmsnorm else 1e-6,\n                outproj_weight=None,\n                outproj_bias=None,\n                headdim=None if self.D_has_hdim else self.headdim,\n                ngroups=self.ngroups,\n                norm_before_gate=self.norm_before_gate,\n                **dt_limit_kwargs,\n            )\n            \n            # (B, D, S)\n            out_bf = rearrange(out_bf, 'b d n -> b n d')\n            out_bf = self.gaussian_decay_mask(out_bf)\n            out_bf = self.silu(out_bf)\n        \n            out_bbw = rearrange(out_bbw, 'b d n -> b n d')\n            out_bbw = self.gaussian_decay_mask(out_bbw)\n            out_bbw = self.silu(out_bbw)\n\n            out_b = torch.cat([out_bf, out_bbw.flip([-1])], dim=-1)\n            out_b = rearrange(out_b, 'b n d -> b d n')\n            out_b = proj2(out_b)\n            skip1 = self.adapool(skip1)\n            \n            out_b = out_b + skip1\n            out_b = rearrange(out_b, 'b d n -> b n d')\n            out_b = out_b.permute(0, 2, 1)\n            out_b = self.norm(out_b)\n            out_b = out_b.permute(0, 2, 1)\n            \n            # -------------------------------- Fusion -------------------------#\n            out = rearrange(self.WMF(out, out_b.flip([-1])) ,'b d n -> b n d')\n            if seqlen_og is not None:\n                out = rearrange(out, \"b l d -> (b l) d\")\n            if self.process_group is not None:\n                reduce_fn = reduce_scatter if self.sequence_parallel else all_reduce\n                out = reduce_fn(out, self.process_group)\n            out = F.linear(out, self.out_proj.weight, self.out_proj.bias)\n            \n        return out\n\n    def step(self, hidden_states, conv_state, ssm_state):\n        dtype = hidden_states.dtype\n        assert hidden_states.shape[1] == 1, \"Only support decoding with 1 token at a time for now\"\n        zxbcdt = self.in_proj(hidden_states.squeeze(1))  # (B 2D)\n        d_mlp = (zxbcdt.shape[-1] - 2 * self.d_ssm - 2 * self.ngroups * self.d_state - self.nheads) // 2\n        z0, x0, z, xBC, dt = torch.split(\n            zxbcdt,\n            [d_mlp, d_mlp, self.d_ssm, self.d_ssm + 2 * self.ngroups * self.d_state, self.nheads],\n            dim=-1\n        )\n\n        # Conv step\n        if causal_conv1d_update is None:\n            conv_state.copy_(torch.roll(conv_state, shifts=-1, dims=-1))  # Update state (B D W)\n            conv_state[:, :, -1] = xBC\n            xBC = torch.sum(conv_state * rearrange(self.conv1d.weight, \"d 1 w -> d w\"), dim=-1)  # (B D)\n            if self.conv1d.bias is not None:\n                xBC = xBC + self.conv1d.bias\n            xBC = self.act(xBC).to(dtype=dtype)\n        else:\n            xBC = causal_conv1d_update(\n                xBC,\n                conv_state,\n                rearrange(self.conv1d.weight, \"d 1 w -> d w\"),\n                self.conv1d.bias,\n                self.activation,\n            )\n\n        x, B, C = torch.split(xBC, [self.d_ssm, self.ngroups * self.d_state, self.ngroups * self.d_state], dim=-1)\n        A = -torch.exp(self.A_log.float())  # (nheads,)\n\n        # SSM step\n        if selective_state_update is None:\n            assert self.ngroups == 1, \"Only support ngroups=1 for this inference code path\"\n            # Discretize A and B\n            dt = F.softplus(dt + self.dt_bias.to(dtype=dt.dtype))  # (batch, nheads)\n            dA = torch.exp(dt * A)  # (batch, nheads)\n            x = rearrange(x, \"b (h p) -> b h p\", p=self.headdim)\n            dBx = torch.einsum(\"bh,bn,bhp->bhpn\", dt, B, x)\n            ssm_state.copy_(ssm_state * rearrange(dA, \"b h -> b h 1 1\") + dBx)\n            y = torch.einsum(\"bhpn,bn->bhp\", ssm_state.to(dtype), C)\n            y = y + rearrange(self.D.to(dtype), \"h -> h 1\") * x\n            y = rearrange(y, \"b h p -> b (h p)\")\n            if not self.rmsnorm:\n                y = y * self.act(z)  # (B D)\n        else:\n            A = repeat(A, \"h -> h p n\", p=self.headdim, n=self.d_state).to(dtype=torch.float32)\n            dt = repeat(dt, \"b h -> b h p\", p=self.headdim)\n            dt_bias = repeat(self.dt_bias, \"h -> h p\", p=self.headdim)\n            D = repeat(self.D, \"h -> h p\", p=self.headdim)\n            B = rearrange(B, \"b (g n) -> b g n\", g=self.ngroups)\n            C = rearrange(C, \"b (g n) -> b g n\", g=self.ngroups)\n            x_reshaped = rearrange(x, \"b (h p) -> b h p\", p=self.headdim)\n            if not self.rmsnorm:\n                z = rearrange(z, \"b (h p) -> b h p\", p=self.headdim)\n            y = selective_state_update(\n                ssm_state, x_reshaped, dt, A, B, C, D, z=z if not self.rmsnorm else None,\n                dt_bias=dt_bias, dt_softplus=True\n            )\n            y = rearrange(y, \"b h p -> b (h p)\")\n        if self.rmsnorm:\n            y = self.norm(y, z)\n        if d_mlp > 0:\n            y = torch.cat([F.silu(z0) * x0, y], dim=-1)\n        out = self.out_proj(y)\n        return out.unsqueeze(1), conv_state, ssm_state\n\n    def allocate_inference_cache(self, batch_size, max_seqlen, dtype=None, **kwargs):\n        device = self.out_proj.weight.device\n        conv_dtype = self.conv1d.weight.dtype if dtype is None else dtype\n        conv_state = torch.zeros(\n            batch_size, self.d_conv, self.conv1d.weight.shape[0], device=device, dtype=conv_dtype\n        ).transpose(1, 2)\n        ssm_dtype = self.in_proj.weight.dtype if dtype is None else dtype\n        ssm_state = torch.zeros(\n            batch_size, self.nheads, self.headdim, self.d_state, device=device, dtype=ssm_dtype\n        )\n        return conv_state, ssm_state\n\n    def _get_states_from_cache(self, inference_params, batch_size, initialize_states=False):\n        assert self.layer_idx is not None\n        if self.layer_idx not in inference_params.key_value_memory_dict:\n            batch_shape = (batch_size,)\n            conv_state = torch.zeros(\n                batch_size,\n                self.d_conv,\n                self.conv1d.weight.shape[0],\n                device=self.conv1d.weight.device,\n                dtype=self.conv1d.weight.dtype,\n            ).transpose(1, 2)\n            ssm_state = torch.zeros(\n                batch_size,\n                self.nheads,\n                self.headdim,\n                self.d_state,\n                device=self.in_proj.weight.device,\n                dtype=self.in_proj.weight.dtype,\n            )\n            inference_params.key_value_memory_dict[self.layer_idx] = (conv_state, ssm_state)\n        else:\n            conv_state, ssm_state = inference_params.key_value_memory_dict[self.layer_idx]\n            # TODO: What if batch size changes between generation, and we reuse the same states?\n            if initialize_states:\n                conv_state.zero_()\n                ssm_state.zero_()\n        return conv_state, ssm_state","metadata":{"execution":{"iopub.status.busy":"2025-01-02T09:31:58.182532Z","iopub.execute_input":"2025-01-02T09:31:58.182804Z","iopub.status.idle":"2025-01-02T09:31:59.933325Z","shell.execute_reply.started":"2025-01-02T09:31:58.182778Z","shell.execute_reply":"2025-01-02T09:31:59.932646Z"},"papermill":{"duration":0.066382,"end_time":"2024-12-02T19:10:39.126908","exception":false,"start_time":"2024-12-02T19:10:39.060526","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Copyright (c) MONAI Consortium\n\nfrom __future__ import annotations\nimport torch.nn as nn\nimport torch \nfrom functools import partial\n\nfrom monai.networks.blocks.dynunet_block import UnetOutBlock\nfrom monai.networks.blocks.unetr_block import UnetrBasicBlock, UnetrUpBlock\nfrom mamba_ssm import Mamba\nimport torch.nn.functional as F \n\nclass LayerNorm(nn.Module):\n    r\"\"\" LayerNorm that supports two data formats: channels_last (default) or channels_first.\n    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with\n    shape (batch_size, height, width, channels) while channels_first corresponds to inputs\n    with shape (batch_size, channels, height, width).\n    \"\"\"\n    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n        super().__init__()\n        self.weight = nn.Parameter(torch.ones(normalized_shape))\n        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n        self.eps = eps\n        self.data_format = data_format\n        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n            raise NotImplementedError\n        self.normalized_shape = (normalized_shape, )\n\n    def forward(self, x):\n        if self.data_format == \"channels_last\":\n            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n        elif self.data_format == \"channels_first\":\n            u = x.mean(1, keepdim=True)\n            s = (x - u).pow(2).mean(1, keepdim=True)\n            x = (x - u) / torch.sqrt(s + self.eps)\n            x = self.weight[:, None, None, None] * x + self.bias[:, None, None, None]\n\n            return x\n\nclass MambaLayer(nn.Module):\n    def __init__(self, dim, d_state = 16, d_conv = 4, expand = 2, num_slices=None):\n        super().__init__()\n        self.dim = dim\n        self.norm = nn.LayerNorm(dim)\n        self.mamba = XMamba(\n                d_model=dim,\n                d_state=d_state, \n                d_conv=d_conv,\n                expand=expand\n        )\n        \n    \n    def forward(self, x):\n        B, C = x.shape[:2]\n        x_skip = x\n        assert C == self.dim\n        n_tokens = x.shape[2:].numel()\n        img_dims = x.shape[2:]\n        x_flat = x.reshape(B, C, n_tokens).transpose(-1, -2)\n        x_norm = self.norm(x_flat)\n        with torch.no_grad():\n            x_mamba = self.mamba(x_norm)\n        out = x_mamba.transpose(-1, -2).reshape(B, C, *img_dims)\n        out = out + x_skip\n        act = nn.GELU()\n        \n        return act(out)\n    \nclass MlpChannel(nn.Module):\n    def __init__(self,hidden_size, mlp_dim, ):\n        super().__init__()\n        self.fc1 = nn.Conv3d(hidden_size, mlp_dim, 1)\n        self.act = nn.GELU()\n        self.fc2 = nn.Conv3d(mlp_dim, hidden_size, 1)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.fc2(x)\n        return x\n\nclass GSC(nn.Module):\n    def __init__(self, in_channels):\n        super().__init__()\n        \n        self.DW_Conv = nn.Sequential(\n            nn.Conv3d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),\n            nn.InstanceNorm3d(in_channels),\n            nn.ReLU()\n        )\n\n        self.PW_Conv = nn.Sequential(\n            nn.Conv3d(in_channels, in_channels, kernel_size=1, stride=1, padding=0),\n            nn.InstanceNorm3d(in_channels),\n            nn.ReLU()\n        )\n    \n    def forward(self, x):\n        res = x\n        x = self.DW_Conv(x)\n        residual = x\n        out = self.PW_Conv(x)\n        out = out + residual\n        return F.relu(out + res)\n\nclass MambaEncoder(nn.Module):\n    def __init__(self, in_chans=1, depths=[2, 2, 2, 2], dims=[64, 128, 256, 512],\n                 drop_path_rate=0., layer_scale_init_value=1e-6, out_indices=[0, 1, 2, 3]):\n        super().__init__()\n\n        self.downsample_layers = nn.ModuleList() # stem and 3 intermediate downsampling conv layers\n        stem = nn.Sequential(\n              nn.Conv3d(in_chans, dims[0], kernel_size=7, stride=2, padding=3),\n        )\n        self.downsample_layers.append(stem)\n        for i in range(3):\n            downsample_layer = nn.Sequential(\n                nn.InstanceNorm3d(dims[i]),\n                nn.Conv3d(dims[i], dims[i+1], kernel_size=2, stride=2),\n            )\n            self.downsample_layers.append(downsample_layer)\n\n        self.stages = nn.ModuleList()\n        self.gscs = nn.ModuleList()\n        num_slices_list = [64, 32, 16, 8]\n        cur = 0\n        for i in range(4):\n            gsc = GSC(dims[i])\n\n            stage = nn.Sequential(\n                *[MambaLayer(dim=dims[i], num_slices=num_slices_list[i]) for j in range(depths[i])]\n            )\n\n            self.stages.append(stage)\n            self.gscs.append(gsc)\n            cur += depths[i]\n\n        self.out_indices = out_indices\n\n        self.mlps = nn.ModuleList()\n        for i_layer in range(4):\n            layer = nn.InstanceNorm3d(dims[i_layer])\n            layer_name = f'norm{i_layer}'\n            self.add_module(layer_name, layer)\n            self.mlps.append(MlpChannel(dims[i_layer], 2 * dims[i_layer]))\n\n    def forward_features(self, x):\n        outs = []\n        for i in range(4):\n            x = self.downsample_layers[i](x)\n            x = self.gscs[i](x)\n            x = self.stages[i](x)\n\n            if i in self.out_indices:\n                norm_layer = getattr(self, f'norm{i}')\n                x_out = norm_layer(x)\n                x_out = self.mlps[i](x_out)\n                outs.append(x_out)\n\n        return tuple(outs)\n\n    def forward(self, x):\n        x = self.forward_features(x)\n        return x\n\nclass SegMamba(nn.Module):\n    def __init__(\n        self,\n        in_chans=1,\n        out_chans=13,\n        depths=[2, 2, 2, 2],\n        feat_size=[64, 128, 256, 512],\n        drop_path_rate=0,\n        layer_scale_init_value=1e-6,\n        hidden_size: int = 768,\n        norm_name = \"instance\",\n        conv_block: bool = True,\n        res_block: bool = True,\n        spatial_dims=3,\n    ) -> None:\n        super().__init__()\n\n        self.hidden_size = hidden_size\n        self.in_chans = in_chans\n        self.out_chans = out_chans\n        self.depths = depths\n        self.drop_path_rate = drop_path_rate\n        self.feat_size = feat_size\n        self.layer_scale_init_value = layer_scale_init_value\n\n        self.spatial_dims = spatial_dims\n        self.vit = MambaEncoder(in_chans, \n                                depths=depths,\n                                dims=feat_size,\n                                drop_path_rate=drop_path_rate,\n                                layer_scale_init_value=layer_scale_init_value,\n                              )\n        self.encoder1 = UnetrBasicBlock(\n            spatial_dims=spatial_dims,\n            in_channels=self.in_chans,\n            out_channels=self.feat_size[0],\n            kernel_size=3,\n            stride=1,\n            norm_name=norm_name,\n            res_block=res_block,\n        )\n        self.encoder2 = UnetrBasicBlock(\n            spatial_dims=spatial_dims,\n            in_channels=self.feat_size[0],\n            out_channels=self.feat_size[1],\n            kernel_size=3,\n            stride=1,\n            norm_name=norm_name,\n            res_block=res_block,\n        )\n        self.encoder3 = UnetrBasicBlock(\n            spatial_dims=spatial_dims,\n            in_channels=self.feat_size[1],\n            out_channels=self.feat_size[2],\n            kernel_size=3,\n            stride=1,\n            norm_name=norm_name,\n            res_block=res_block,\n        )\n        self.encoder4 = UnetrBasicBlock(\n            spatial_dims=spatial_dims,\n            in_channels=self.feat_size[2],\n            out_channels=self.feat_size[3],\n            kernel_size=3,\n            stride=1,\n            norm_name=norm_name,\n            res_block=res_block,\n        )\n\n        self.encoder5 = UnetrBasicBlock(\n            spatial_dims=spatial_dims,\n            in_channels=self.feat_size[3],\n            out_channels=self.hidden_size,\n            kernel_size=3,\n            stride=1,\n            norm_name=norm_name,\n            res_block=res_block,\n        )\n\n        self.decoder5 = UnetrUpBlock(\n            spatial_dims=spatial_dims,\n            in_channels=self.hidden_size,\n            out_channels=self.feat_size[3],\n            kernel_size=3,\n            upsample_kernel_size=2,\n            norm_name=norm_name,\n            res_block=res_block,\n        )\n        self.decoder4 = UnetrUpBlock(\n            spatial_dims=spatial_dims,\n            in_channels=self.feat_size[3],\n            out_channels=self.feat_size[2],\n            kernel_size=3,\n            upsample_kernel_size=2,\n            norm_name=norm_name,\n            res_block=res_block,\n        )\n        self.decoder3 = UnetrUpBlock(\n            spatial_dims=spatial_dims,\n            in_channels=self.feat_size[2],\n            out_channels=self.feat_size[1],\n            kernel_size=3,\n            upsample_kernel_size=2,\n            norm_name=norm_name,\n            res_block=res_block,\n        )\n        self.decoder2 = UnetrUpBlock(\n            spatial_dims=spatial_dims,\n            in_channels=self.feat_size[1],\n            out_channels=self.feat_size[0],\n            kernel_size=3,\n            upsample_kernel_size=2,\n            norm_name=norm_name,\n            res_block=res_block,\n        )\n        self.decoder1 = UnetrBasicBlock(\n            spatial_dims=spatial_dims,\n            in_channels=self.feat_size[0],\n            out_channels=self.feat_size[0],\n            kernel_size=3,\n            stride=1,\n            norm_name=norm_name,\n            res_block=res_block,\n        )\n        self.out = UnetOutBlock(spatial_dims=spatial_dims, in_channels=64, out_channels=self.out_chans)\n\n    def forward(self, x_in):\n        outs = self.vit(x_in)\n        enc1 = self.encoder1(x_in)\n        x2 = outs[0]\n        enc2 = self.encoder2(x2)\n        x3 = outs[1]\n        enc3 = self.encoder3(x3)\n        x4 = outs[2]\n        enc4 = self.encoder4(x4)\n        enc_hidden = self.encoder5(outs[3])\n        dec3 = self.decoder5(enc_hidden, enc4)\n        dec2 = self.decoder4(dec3, enc3)\n        dec1 = self.decoder3(dec2, enc2)\n        dec0 = self.decoder2(dec1, enc1)\n        out = self.decoder1(dec0)\n                \n        return self.out(out)","metadata":{"execution":{"iopub.status.busy":"2025-01-02T09:31:59.934201Z","iopub.execute_input":"2025-01-02T09:31:59.934460Z","iopub.status.idle":"2025-01-02T09:31:59.960695Z","shell.execute_reply.started":"2025-01-02T09:31:59.934436Z","shell.execute_reply":"2025-01-02T09:31:59.959891Z"},"papermill":{"duration":0.045705,"end_time":"2024-12-02T19:10:39.212384","exception":false,"start_time":"2024-12-02T19:10:39.166679","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"","metadata":{"execution":{"iopub.status.busy":"2025-01-02T09:31:59.961578Z","iopub.execute_input":"2025-01-02T09:31:59.961864Z","iopub.status.idle":"2025-01-02T09:31:59.984810Z","shell.execute_reply.started":"2025-01-02T09:31:59.961836Z","shell.execute_reply":"2025-01-02T09:31:59.984044Z"},"papermill":{"duration":0.019475,"end_time":"2024-12-02T19:10:39.245397","exception":false,"start_time":"2024-12-02T19:10:39.225922","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## Optimizer and loss function","metadata":{"papermill":{"duration":0.013057,"end_time":"2024-12-02T19:10:39.272274","exception":false,"start_time":"2024-12-02T19:10:39.259217","status":"completed"},"tags":[]}},{"cell_type":"code","source":"max_epochs = 250\nval_interval = 1\nVAL_AMP = True\nroi = (128, 128, 128)\n\ndevice = torch.device(\"cuda\")\nmodel = SegMamba(in_chans=4,\n                 out_chans=4,\n                 depths=[2,2,2,2],\n                 feat_size=[64, 128, 256, 512]).to(device)\n\n# define inference method\ndef inference(input):\n    def _compute(input):\n        return sliding_window_inference(\n            inputs=input,\n            roi_size=(128, 128, 128),\n            sw_batch_size=1,\n            predictor=model,\n            overlap=0.5,\n        )\n\n    if VAL_AMP:\n        with torch.amp.autocast(device_type='cuda'):\n            return _compute(input)\n    else:\n        return _compute(input)\n","metadata":{"execution":{"iopub.status.busy":"2025-01-02T09:31:59.985679Z","iopub.execute_input":"2025-01-02T09:31:59.985955Z","iopub.status.idle":"2025-01-02T09:32:01.402502Z","shell.execute_reply.started":"2025-01-02T09:31:59.985928Z","shell.execute_reply":"2025-01-02T09:32:01.401572Z"},"papermill":{"duration":0.998368,"end_time":"2024-12-02T19:10:40.283874","exception":false,"start_time":"2024-12-02T19:10:39.285506","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## Create test set dataloader","metadata":{"papermill":{"duration":0.030428,"end_time":"2024-12-03T06:33:40.241216","exception":false,"start_time":"2024-12-03T06:33:40.210788","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Các modal cần xử lý\nmodalities = [\"t1n\", \"t1c\", \"t2f\", \"t2w\"]\n\n# Tạo danh sách test_files tự động\ntest_files = [\n    {\n        \"image\": [\n            f\"/kaggle/input/brats2024-small-dataset/BraTS2024_small_dataset/BraTS-GLI-02062-102/BraTS-GLI-02062-102-{modality}.nii\"\n            for modality in modalities\n        ],\n        \"label\": \"/kaggle/input/brats2024-small-dataset/BraTS2024_small_dataset/BraTS-GLI-02062-102/BraTS-GLI-02062-102-seg.nii\",\n    }\n]\n\ntest_transform = Compose(\n    [\n        LoadImaged(keys=[\"image\", \"label\"]),\n        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n    ]\n)\n\ntest_ds = Dataset(data=test_files, transform=test_transform)\n\ntest_loader = DataLoader(\n    test_ds,\n    batch_size=1,\n    shuffle=False,\n    num_workers=8,\n    pin_memory=True,\n)","metadata":{"papermill":{"duration":0.04174,"end_time":"2024-12-03T06:33:40.313908","exception":false,"start_time":"2024-12-03T06:33:40.272168","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T09:36:58.938169Z","iopub.execute_input":"2025-01-02T09:36:58.938568Z","iopub.status.idle":"2025-01-02T09:36:58.946672Z","shell.execute_reply.started":"2025-01-02T09:36:58.938515Z","shell.execute_reply":"2025-01-02T09:36:58.945904Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"## Load the best saved checkpoint and perform inference \n\n\n\nWe select a single case from the validation set and perform inference to compare the model segmentation output with the corresponding label. ","metadata":{"papermill":{"duration":0.030318,"end_time":"2024-12-03T06:33:40.375590","exception":false,"start_time":"2024-12-03T06:33:40.345272","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model.load_state_dict(torch.load(os.path.join(\"/kaggle/input/model-xmamba300/model_xMamba300.pt\"))[\"state_dict\"], strict=False)\nmodel.to(device)\nmodel.eval()\n\nwith torch.no_grad():\n    for batch_data in test_loader:\n        image = batch_data[\"image\"].to(device)\n        prob = torch.sigmoid(inference(image))\n        seg = prob[0].detach().cpu().numpy()\n        seg = (seg > 0.5).astype(np.int8)\n        seg_out = np.zeros((seg.shape[1], seg.shape[2], seg.shape[3]))\n        seg_out[seg[1] == 1] = 2\n        seg_out[seg[0] == 1] = 1\n        seg_out[seg[2] == 1] = 3\n        seg_out[seg[3] == 1] = 4","metadata":{"papermill":{"duration":112.713656,"end_time":"2024-12-03T06:35:33.119281","exception":false,"start_time":"2024-12-03T06:33:40.405625","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T09:37:02.235017Z","iopub.execute_input":"2025-01-02T09:37:02.235335Z","iopub.status.idle":"2025-01-02T09:37:17.801159Z","shell.execute_reply.started":"2025-01-02T09:37:02.235306Z","shell.execute_reply":"2025-01-02T09:37:17.800138Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-24-63036a061a47>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(os.path.join(\"/kaggle/input/model-xmamba300/model_xMamba300.pt\"))[\"state_dict\"], strict=False)\n/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"slice_num = 115\n\nimg_add = os.path.join(\"/kaggle/input/brats2024-small-dataset/BraTS2024_small_dataset/BraTS-GLI-02062-102/BraTS-GLI-02062-102-t1c.nii\")\n\nlabel_add = os.path.join(\"/kaggle/input/brats2024-small-dataset/BraTS2024_small_dataset/BraTS-GLI-02062-102/BraTS-GLI-02062-102-seg.nii\")\n\nimg = nib.load(img_add).get_fdata()\n\nlabel = nib.load(label_add).get_fdata()\n\nplt.figure(\"image\", (18, 6))\n\nplt.subplot(1, 3, 1)\n\nplt.title(\"image\")\n\nplt.imshow(img[:, :, slice_num], cmap=\"gray\")\n\nplt.subplot(1, 3, 2)\n\nplt.title(\"label\")\n\nplt.imshow(label[:, :, slice_num])\n\nplt.subplot(1, 3, 3)\n\nplt.title(\"segmentation\")\n\nplt.imshow(seg_out[:, :, slice_num])\n\nplt.show()","metadata":{"papermill":{"duration":0.726116,"end_time":"2024-12-03T06:35:51.235416","exception":false,"start_time":"2024-12-03T06:35:50.509300","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T09:38:54.602701Z","iopub.execute_input":"2025-01-02T09:38:54.603026Z","iopub.status.idle":"2025-01-02T09:38:55.226251Z","shell.execute_reply.started":"2025-01-02T09:38:54.602997Z","shell.execute_reply":"2025-01-02T09:38:55.225347Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1800x600 with 3 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":34},{"cell_type":"markdown","source":"## Visualize segmentation output and compare with label","metadata":{"papermill":{"duration":0.037265,"end_time":"2024-12-03T06:35:33.196823","exception":false,"start_time":"2024-12-03T06:35:33.159558","status":"completed"},"tags":[]}},{"cell_type":"code","source":"with torch.no_grad():\n    # select one image to evaluate and visualize the model output\n    val_input = val_ds[3][\"image\"].unsqueeze(0).to(device)\n    roi_size = (128, 128, 128)\n    sw_batch_size = 4\n    val_output = inference(val_input)\n    val_output = post_trans(val_output[0])\n    plt.figure(\"image\", (24, 6))\n    for i in range(4):\n        plt.subplot(1, 4, i + 1)\n        plt.title(f\"image channel {i}\")\n        plt.imshow(val_ds[3][\"image\"][i, :, :, 64].detach().cpu(), cmap=\"gray\")\n    plt.show()\n    # visualize the 4 channels label corresponding to this image\n    plt.figure(\"label\", (18, 6))\n    for i in range(4):\n        plt.subplot(1, 4, i + 1)\n        plt.title(f\"label channel {i}\")\n        plt.imshow(val_ds[3][\"label\"][i, :, :, 64].detach().cpu())\n    plt.show()\n    # visualize the 4 channels model output corresponding to this image\n    plt.figure(\"output\", (18, 6))\n    for i in range(4):\n        plt.subplot(1, 4, i + 1)\n        plt.title(f\"output channel {i}\")\n        plt.imshow(val_output[i, :, :, 64].detach().cpu())\n    plt.show()","metadata":{"papermill":{"duration":17.243915,"end_time":"2024-12-03T06:35:50.475605","exception":false,"start_time":"2024-12-03T06:35:33.231690","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T09:34:54.137121Z","iopub.execute_input":"2025-01-02T09:34:54.137447Z","iopub.status.idle":"2025-01-02T09:34:54.189058Z","shell.execute_reply.started":"2025-01-02T09:34:54.137418Z","shell.execute_reply":"2025-01-02T09:34:54.187678Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-11f5c26c73d1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# select one image to evaluate and visualize the model output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mval_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mroi_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msw_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'val_ds' is not defined"],"ename":"NameError","evalue":"name 'val_ds' is not defined","output_type":"error"}],"execution_count":22}]}